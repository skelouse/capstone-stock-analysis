{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#NetworkCreator-Docstring\" data-toc-modified-id=\"NetworkCreator-Docstring-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>NetworkCreator Docstring</a></span></li><li><span><a href=\"#Sample-code\" data-toc-modified-id=\"Sample-code-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Sample code</a></span></li><li><span><a href=\"#Walkthrough\" data-toc-modified-id=\"Walkthrough-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Walkthrough</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-prediction-columns\" data-toc-modified-id=\"Define-prediction-columns-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Define prediction columns</a></span></li><li><span><a href=\"#Define-number-of-days-to-predict-with\" data-toc-modified-id=\"Define-number-of-days-to-predict-with-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Define number of days to predict with</a></span></li><li><span><a href=\"#Define-parameters\" data-toc-modified-id=\"Define-parameters-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Define parameters</a></span></li><li><span><a href=\"#Instantiate-creator\" data-toc-modified-id=\"Instantiate-creator-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Instantiate creator</a></span></li><li><span><a href=\"#Prepare-data\" data-toc-modified-id=\"Prepare-data-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Prepare data</a></span><ul class=\"toc-item\"><li><span><a href=\"#def-clean_cols\" data-toc-modified-id=\"def-clean_cols-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>def clean_cols</a></span></li><li><span><a href=\"#def-split_dataframe\" data-toc-modified-id=\"def-split_dataframe-4.5.2\"><span class=\"toc-item-num\">4.5.2&nbsp;&nbsp;</span>def split_dataframe</a></span></li><li><span><a href=\"#def-split_and_scale_dataframes\" data-toc-modified-id=\"def-split_and_scale_dataframes-4.5.3\"><span class=\"toc-item-num\">4.5.3&nbsp;&nbsp;</span>def split_and_scale_dataframes</a></span></li><li><span><a href=\"#def-reshape_data\" data-toc-modified-id=\"def-reshape_data-4.5.4\"><span class=\"toc-item-num\">4.5.4&nbsp;&nbsp;</span>def reshape_data</a></span></li><li><span><a href=\"#def-create_TS_generators\" data-toc-modified-id=\"def-create_TS_generators-4.5.5\"><span class=\"toc-item-num\">4.5.5&nbsp;&nbsp;</span>def create_TS_generators</a></span></li></ul></li><li><span><a href=\"#def-build_and_fit_model\" data-toc-modified-id=\"def-build_and_fit_model-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>def build_and_fit_model</a></span></li><li><span><a href=\"#Fit\" data-toc-modified-id=\"Fit-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Fit</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here we will be walking through how the NetworkCreator actually works by breaking out the code from the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.217628Z",
     "start_time": "2021-01-15T06:53:23.616099Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from modeling.create import NetworkCreator\n",
    "df = pd.read_pickle(\"./data/modeling/model_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.263615Z",
     "start_time": "2021-01-15T06:53:27.218621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_RevenueTTM</th>\n",
       "      <th>A_TotalCash</th>\n",
       "      <th>A_ExDividendDate</th>\n",
       "      <th>A_Dividend</th>\n",
       "      <th>A_DividendYield</th>\n",
       "      <th>A_PriceToBook</th>\n",
       "      <th>A_PriceToSales</th>\n",
       "      <th>A_EnterpriseValue</th>\n",
       "      <th>A_PriceToCashFlow</th>\n",
       "      <th>A_PE</th>\n",
       "      <th>...</th>\n",
       "      <th>ZTS_McLeanCapital</th>\n",
       "      <th>ZTS_NedDavis</th>\n",
       "      <th>ZTS_TradingCentral</th>\n",
       "      <th>ZTS_Zacks</th>\n",
       "      <th>ZTS_SPValuation</th>\n",
       "      <th>ZTS_SPQuality</th>\n",
       "      <th>ZTS_SPGrowthStability</th>\n",
       "      <th>ZTS_SPFinancialHealth</th>\n",
       "      <th>ZTS_ThomsonReutersVerus</th>\n",
       "      <th>ZTS_ThomsonReutersIBES</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-09</th>\n",
       "      <td>5019.0</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.94402</td>\n",
       "      <td>4.29809</td>\n",
       "      <td>4.40182</td>\n",
       "      <td>2.167070e+10</td>\n",
       "      <td>16.57368</td>\n",
       "      <td>19.8</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>88.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-12</th>\n",
       "      <td>5019.0</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.95571</td>\n",
       "      <td>4.24551</td>\n",
       "      <td>4.34797</td>\n",
       "      <td>2.140126e+10</td>\n",
       "      <td>16.37095</td>\n",
       "      <td>19.2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>88.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-13</th>\n",
       "      <td>5019.0</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.98454</td>\n",
       "      <td>4.12119</td>\n",
       "      <td>4.22065</td>\n",
       "      <td>2.076411e+10</td>\n",
       "      <td>15.89156</td>\n",
       "      <td>19.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-14</th>\n",
       "      <td>5019.0</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.96984</td>\n",
       "      <td>4.18366</td>\n",
       "      <td>4.28463</td>\n",
       "      <td>2.108427e+10</td>\n",
       "      <td>16.13245</td>\n",
       "      <td>18.9</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-15</th>\n",
       "      <td>5090.0</td>\n",
       "      <td>1765.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>1.00015</td>\n",
       "      <td>4.28332</td>\n",
       "      <td>4.06782</td>\n",
       "      <td>2.036590e+10</td>\n",
       "      <td>16.05056</td>\n",
       "      <td>20.8</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 13545 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            A_RevenueTTM  A_TotalCash  A_ExDividendDate  A_Dividend  \\\n",
       "date                                                                  \n",
       "2019-08-09        5019.0       2155.0                 0       0.164   \n",
       "2019-08-12        5019.0       2155.0                 0       0.164   \n",
       "2019-08-13        5019.0       2155.0                 0       0.164   \n",
       "2019-08-14        5019.0       2155.0                 0       0.164   \n",
       "2019-08-15        5090.0       1765.0                 0       0.164   \n",
       "\n",
       "            A_DividendYield  A_PriceToBook  A_PriceToSales  A_EnterpriseValue  \\\n",
       "date                                                                            \n",
       "2019-08-09          0.94402        4.29809         4.40182       2.167070e+10   \n",
       "2019-08-12          0.95571        4.24551         4.34797       2.140126e+10   \n",
       "2019-08-13          0.98454        4.12119         4.22065       2.076411e+10   \n",
       "2019-08-14          0.96984        4.18366         4.28463       2.108427e+10   \n",
       "2019-08-15          1.00015        4.28332         4.06782       2.036590e+10   \n",
       "\n",
       "            A_PriceToCashFlow  A_PE  ...  ZTS_McLeanCapital  ZTS_NedDavis  \\\n",
       "date                                 ...                                    \n",
       "2019-08-09           16.57368  19.8  ...                3.0           3.0   \n",
       "2019-08-12           16.37095  19.2  ...                3.0           3.0   \n",
       "2019-08-13           15.89156  19.5  ...                3.0           3.0   \n",
       "2019-08-14           16.13245  18.9  ...                3.0           3.0   \n",
       "2019-08-15           16.05056  20.8  ...                3.0           3.0   \n",
       "\n",
       "            ZTS_TradingCentral  ZTS_Zacks  ZTS_SPValuation  ZTS_SPQuality  \\\n",
       "date                                                                        \n",
       "2019-08-09                   1          3             88.0           87.0   \n",
       "2019-08-12                   1          3             88.0           87.0   \n",
       "2019-08-13                   1          5             88.0           87.0   \n",
       "2019-08-14                   1          5             88.0           87.0   \n",
       "2019-08-15                   1          5             88.0           87.0   \n",
       "\n",
       "            ZTS_SPGrowthStability  ZTS_SPFinancialHealth  \\\n",
       "date                                                       \n",
       "2019-08-09                   30.0                   58.0   \n",
       "2019-08-12                   30.0                   58.0   \n",
       "2019-08-13                   28.0                   56.0   \n",
       "2019-08-14                   28.0                   56.0   \n",
       "2019-08-15                   30.0                   57.0   \n",
       "\n",
       "            ZTS_ThomsonReutersVerus  ZTS_ThomsonReutersIBES  \n",
       "date                                                         \n",
       "2019-08-09                      3.0                   1.941  \n",
       "2019-08-12                      3.0                   1.941  \n",
       "2019-08-13                      3.0                   1.941  \n",
       "2019-08-14                      3.0                   1.941  \n",
       "2019-08-15                      3.0                   1.941  \n",
       "\n",
       "[5 rows x 13545 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetworkCreator Docstring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\"\"\"\n",
    "    For creating a Time Series predicting neural network\n",
    "    Used for\n",
    "        - tuning model parameters\n",
    "        - testing tuned parameters\n",
    "        - cleaning the TS data\n",
    "        - delivering model reports\n",
    "\n",
    "    Parameters\n",
    "    ----------------------------------------\n",
    "    df{pd.DataFrame}::\n",
    "        A dataframe consisting of X_cols and y_cols\n",
    "    X_cols[list, str]::\n",
    "        Either uses a list to directly slice the\n",
    "        data and targets, OR uses all columns that\n",
    "        contain the supplied string.\n",
    "    y_cols[list, str]::\n",
    "        Either uses a list to directly slice the\n",
    "        data and targets, OR uses all columns that\n",
    "        contain the supplied string.\n",
    "    n_days(int)::\n",
    "        Number of days to use in each days prediction\n",
    "        EX:)  if n_days was 3\n",
    "            - slice targets[3:]\n",
    "            - use data[0:4] to predict first target\n",
    "            - data[1:5] to predict next target\n",
    "            - ...\n",
    "    test_split=0.3(float 0-1)::\n",
    "        The decimal percentage to split the\n",
    "        test data on\n",
    "    val_split=0.05(float 0-1)::\n",
    "        The decimal percentage to split the\n",
    "        val data on\n",
    "\n",
    "    Example Usage\n",
    "    ----------------------------------------\n",
    "    # Import libraries\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> import seaborn as sns\n",
    "    >>> import pandas as pd\n",
    "\n",
    "    # Load dataset\n",
    "    >>> flights = sns.load_dataset('flights')\n",
    "\n",
    "    # Define n_years could also be n_days\n",
    "    >>> n_years = 1\n",
    "\n",
    "    # Map month strings to 0-12\n",
    "    >>> month_map = flights['month'][:12].reset_index(drop=True).to_dict()\n",
    "    >>> flights['month'] = flights['month'].map(month_map)\n",
    "\n",
    "    # Instantiate NetworkCreator\n",
    "    >>> creator = NetworkCreator(flights, 'month', 'passengers', n_years)\n",
    "\n",
    "    # build and fit model ( With default parameters )\n",
    "    >>> creator.build_and_fit_model(dummy_hp=True)\n",
    "\n",
    "    # Fit model\n",
    "    >>> history = creator.model.fit(\n",
    "    >>>     creator.train_data_gen,\n",
    "    >>>     validation_data=creator.val_data_gen,\n",
    "    >>>     epochs=10)\n",
    "\n",
    "    # Plot the loss and val_loss\n",
    "    >>> plt.plot(history.history['loss'])\n",
    "    >>> plt.plot(history.history['val_loss'])\n",
    "    >>> plt.legend(['train', 'test'])\n",
    "    >>> plt.show()\n",
    " \"\"\"\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample code\n",
    "> Below is sample code for how we would use the NetworkCreator class.  We will be walking through how it works below\n",
    "\n",
    "```python\n",
    "# Define prediction columns\n",
    "X_cols = [col for col in model_df.columns if 'AAPL' in col]\n",
    "y_cols = 'AAPL_price'\n",
    "\n",
    "# Define number of days to predict with\n",
    "n_days = 1\n",
    "\n",
    "# Define parameters\n",
    "parameters = {\n",
    "    'use_input_regularizer': 0,\n",
    "    'input_dropout_rate': 0.1,\n",
    "    'use_hidden_regularizer': 0,\n",
    "    'hidden_dropout_rate': 0.5,\n",
    "    'n_hidden_layers': 1,\n",
    "    'hidden_neurons': 32,\n",
    "    'patience': 5,\n",
    "    'use_early_stopping': 0,\n",
    "    'batch_size': 32,\n",
    "    'input_regularizer_penalty': 0.1,\n",
    "    'hidden_regularizer_penalty': 0.3\n",
    "                  }\n",
    "\n",
    "# Instantiate creator\n",
    "creator = NetworkCreator(df, X_cols, y_cols, n_days)\n",
    "\n",
    "# Build and facade fit model with base parameters\n",
    "creator.build_and_fit_model(**parameters, dummy_hp=True)\n",
    "\n",
    "# Real fit model\n",
    "history = creator.model.fit(\n",
    "    creator.train_data_gen,\n",
    "    validation_data=creator.val_data_gen,\n",
    "    epochs=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define prediction columns\n",
    "> First we will be defining the columns we want as features and targets.  For the features or `X_cols` you'll see `AAPL`  this will use every column with `AAPL` in it as the features.  For the `y_cols` you can see `AAPL_price` this will use only the price of apple column for the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.279619Z",
     "start_time": "2021-01-15T06:53:27.264619Z"
    }
   },
   "outputs": [],
   "source": [
    "X_cols = 'AAPL'\n",
    "y_cols = 'AAPL_price'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T19:50:24.759008Z",
     "start_time": "2021-01-12T19:50:24.743010Z"
    }
   },
   "source": [
    "## Define number of days to predict with\n",
    "> Next we'll define n_days:\n",
    "> - This defines how many previous days to use in the prediction.  If n_days is 3 it would use the previous 3 days to predict the next and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.295615Z",
     "start_time": "2021-01-15T06:53:27.280616Z"
    }
   },
   "outputs": [],
   "source": [
    "n_days = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters\n",
    "> Next we'll define the parameters; more on this later, but for a gist this is how the actual network is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.310616Z",
     "start_time": "2021-01-15T06:53:27.296618Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'use_input_regularizer': 0,\n",
    "    'input_dropout_rate': 0.1,\n",
    "    'use_hidden_regularizer': 0,\n",
    "    'hidden_dropout_rate': 0.5,\n",
    "    'n_hidden_layers': 1,\n",
    "    'hidden_neurons': 32,\n",
    "    'patience': 5,\n",
    "    'use_early_stopping': 0,\n",
    "    'batch_size': 32,\n",
    "    'input_regularizer_penalty': 0.1,\n",
    "    'hidden_regularizer_penalty': 0.3\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T19:55:00.500163Z",
     "start_time": "2021-01-12T19:55:00.487164Z"
    }
   },
   "source": [
    "## Instantiate creator\n",
    "> Now for the fun part, here is where we actually instantiate the creator,  you'll see below what is ran in the \\_\\_init__ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.373618Z",
     "start_time": "2021-01-15T06:53:27.311616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 35 X columns\n",
      "Got 1 y columns\n",
      "target is in data\n"
     ]
    }
   ],
   "source": [
    "creator = NetworkCreator(df, X_cols, y_cols, n_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T20:01:26.742163Z",
     "start_time": "2021-01-12T20:01:26.726164Z"
    }
   },
   "source": [
    "```python\n",
    "def __init__(self, df, X_cols, y_cols, n_days,\n",
    "                 test_split=0.3, val_split=0.05,\n",
    "                 tuning=False, verbose=True):\n",
    "    self.model = None\n",
    "    self.df = df\n",
    "    self.X_cols = X_cols\n",
    "    self.y_cols = y_cols\n",
    "    self.test_split = test_split\n",
    "    self.val_split = val_split\n",
    "    self.tuning = tuning\n",
    "    self.verbose = verbose\n",
    "    if tuning:\n",
    "        self.prepare_data_gen(n_days)\n",
    "    else:\n",
    "        self.prepare_data(n_days)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can see other than creating the instance variables a prepare_data is called.  `we'll ignore the if tuning for now` so let's check prepare_data out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.389615Z",
     "start_time": "2021-01-15T06:53:27.374618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method prepare_data in module modeling.create:\n",
      "\n",
      "prepare_data(n_days=1) method of modeling.create.NetworkCreator instance\n",
      "    Runs in initialization\n",
      "    calls\n",
      "      - clean_cols\n",
      "      - split_dataframe\n",
      "      - split_and_scale_dataframes\n",
      "      - reshape data\n",
      "      - create_TS_generators\n",
      "      - initializes input_shape\n",
      "            (n_input, X_n_features)\n",
      "    \n",
      "    Parameters\n",
      "    ----------------------------------------\n",
      "    n_days(int)::\n",
      "        Number of time periods to use in prediction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(creator.prepare_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def prepare_data(self, n_days=1):\n",
    "        self.clean_cols()\n",
    "\n",
    "        # Splits dataframe to X_cols + y_cols only,\n",
    "        # and to train, test, val\n",
    "        self.split_dataframe(self.test_split, self.val_split)\n",
    "\n",
    "        # Get column indices\n",
    "        self.column_indices = \\\n",
    "            {name: i for i, name in enumerate(self.df.columns)}\n",
    "\n",
    "        # Scale data X_train, etc is not scaled\n",
    "        # Scalers are created for inverse reference\n",
    "        self.split_and_scale_dataframes()\n",
    "\n",
    "        # Reshape data, creates X_train->val_reshaped\n",
    "        self.reshape_data()\n",
    "\n",
    "        # Initialize n_input\n",
    "        self.n_input = n_days\n",
    "\n",
    "        # Create Time Series Generators\n",
    "        if self.val_split:\n",
    "            self.train_data_gen, self.test_data_gen, self.val_data_gen = \\\n",
    "                self.create_TS_generators(n_days=n_days)\n",
    "        elif self.tuning:\n",
    "            self.data_gen = self.create_TS_generators(n_days=n_days)\n",
    "        else:\n",
    "            self.train_data_gen, self.test_data_gen = \\\n",
    "                self.create_TS_generators(n_days=n_days)\n",
    "\n",
    "        # Define input shape for model\n",
    "        self.input_shape = (self.n_input,\n",
    "                            self.X_n_features)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we'll walk through each step of the prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def clean_cols\n",
    "> If you remember before we simply plugged in strings to creator for the X_cols and y_cols.  `clean_cols` takes those strings and transforms it into actual column names from the provided df as you'll see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.404618Z",
     "start_time": "2021-01-15T06:53:27.391618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method clean_cols in module modeling.create:\n",
      "\n",
      "clean_cols() method of modeling.create.NetworkCreator instance\n",
      "    If a string is given for cols then it will take all of the columns\n",
      "    that are in the dataframe that contain that string\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(creator.clean_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T20:18:23.240882Z",
     "start_time": "2021-01-12T20:18:23.227882Z"
    }
   },
   "source": [
    "```python\n",
    "    def clean_cols(self):\n",
    "        if isinstance(self.X_cols, str):\n",
    "            self.X_cols = \\\n",
    "                [col for col in self.df.columns if self.X_cols in col]\n",
    "            if self.verbose:\n",
    "                print(\"Got\", len(self.X_cols), \"X columns\")\n",
    "\n",
    "        if isinstance(self.y_cols, str):\n",
    "            self.y_cols = \\\n",
    "                [col for col in self.df.columns if self.y_cols in col]\n",
    "            if self.verbose:\n",
    "                print(\"Got\", len(self.y_cols), \"y columns\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we can see that our X_cols are all columns with AAPL in it, and our y_cols is AAPL_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.419616Z",
     "start_time": "2021-01-15T06:53:27.405617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL_RevenueTTM',\n",
       " 'AAPL_TotalCash',\n",
       " 'AAPL_ExDividendDate',\n",
       " 'AAPL_Dividend',\n",
       " 'AAPL_DividendYield',\n",
       " 'AAPL_PriceToBook',\n",
       " 'AAPL_PriceToSales',\n",
       " 'AAPL_EnterpriseValue',\n",
       " 'AAPL_PriceToCashFlow',\n",
       " 'AAPL_PE',\n",
       " 'AAPL_ReturnonEquity',\n",
       " 'AAPL_FreeCashFlow',\n",
       " 'AAPL_TotalDebtToEquity',\n",
       " 'AAPL_PricePerformance52Weeks',\n",
       " 'AAPL_PricePerformanceYTD',\n",
       " 'AAPL_TotalReturn1Yr',\n",
       " 'AAPL_TotalReturn3Yr',\n",
       " 'AAPL_VolumeAvg90Day',\n",
       " 'AAPL_price',\n",
       " 'AAPL_Argus',\n",
       " 'AAPL_StarMine',\n",
       " 'AAPL_ColumbineCapital',\n",
       " 'AAPL_FordEquityResearch',\n",
       " 'AAPL_ISSEVA',\n",
       " 'AAPL_Jefferson',\n",
       " 'AAPL_McLeanCapital',\n",
       " 'AAPL_NedDavis',\n",
       " 'AAPL_TradingCentral',\n",
       " 'AAPL_Zacks',\n",
       " 'AAPL_SPValuation',\n",
       " 'AAPL_SPQuality',\n",
       " 'AAPL_SPGrowthStability',\n",
       " 'AAPL_SPFinancialHealth',\n",
       " 'AAPL_ThomsonReutersVerus',\n",
       " 'AAPL_ThomsonReutersIBES']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.X_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.435616Z",
     "start_time": "2021-01-15T06:53:27.420616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL_price']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.y_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def split_dataframe\n",
    "> Now we're going to go over the split_dataframe.  This is used to split the data frame into the respective train_df test_df and val_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.451615Z",
     "start_time": "2021-01-15T06:53:27.436620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method split_dataframe in module modeling.create:\n",
      "\n",
      "split_dataframe(test_split=0.3, val_split=0.05) method of modeling.create.NetworkCreator instance\n",
      "    Splits the dataframe on defined X_cols and y_cols\n",
      "    after that splitting on test_split and val_split.\n",
      "    \n",
      "    Parameters\n",
      "    ----------------------------------------\n",
      "    test_split{float 0-1}::\n",
      "      - the percentage of the data to use for testing\n",
      "    val_split{float 0-1}::\n",
      "      - the percentage of the data to us for validation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(creator.split_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def split_dataframe(self, test_split=.3, val_split=.05):\n",
    "        try:\n",
    "            if len(self.y_cols) == 1:\n",
    "                if self.verbose:\n",
    "                    print(\"target is in data\")\n",
    "                select_cols = self.X_cols + self.y_cols\n",
    "                self.df = self.df[select_cols]\n",
    "\n",
    "            elif self.X_cols == self.y_cols:\n",
    "                if self.verbose:\n",
    "                    print('target(s) equal data')\n",
    "                self.df = self.df[self.X_cols]\n",
    "\n",
    "            elif set(self.y_cols).issubset(self.X_cols):\n",
    "                if self.verbose:\n",
    "                    print(\"targets are in x\")\n",
    "                self.df = self.df[self.X_cols]\n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print('target is not in data')\n",
    "                select_cols = self.X_cols + self.y_cols\n",
    "                self.df = self.df[select_cols]\n",
    "\n",
    "        except TypeError:\n",
    "            if self.verbose:\n",
    "                print('y is in dataframe but not x')\n",
    "            select_cols = self.X_cols + self.y_cols\n",
    "            self.df = self.df[select_cols]\n",
    "        \n",
    "        # Execution saver, only need data_gen when tuning\n",
    "        if self.tuning:\n",
    "            return 1\n",
    "        # Split dataframes\n",
    "        if val_split:\n",
    "            train, val, test = self.split_perc(self.df, test_split, val_split)\n",
    "            self.df_train = train\n",
    "            self.df_test = test\n",
    "            self.df_val = val\n",
    "        else:\n",
    "            train, test = self.split_perc(self.df, test_split, val_split=0)\n",
    "            self.df_train = train\n",
    "            self.df_test = test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can see that the self.df is broken up into only that which contains the X_cols and y_cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.467616Z",
     "start_time": "2021-01-15T06:53:27.452616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AAPL_RevenueTTM', 'AAPL_TotalCash', 'AAPL_ExDividendDate',\n",
       "       'AAPL_Dividend', 'AAPL_DividendYield', 'AAPL_PriceToBook',\n",
       "       'AAPL_PriceToSales', 'AAPL_EnterpriseValue', 'AAPL_PriceToCashFlow',\n",
       "       'AAPL_PE', 'AAPL_ReturnonEquity', 'AAPL_FreeCashFlow',\n",
       "       'AAPL_TotalDebtToEquity', 'AAPL_PricePerformance52Weeks',\n",
       "       'AAPL_PricePerformanceYTD', 'AAPL_TotalReturn1Yr',\n",
       "       'AAPL_TotalReturn3Yr', 'AAPL_VolumeAvg90Day', 'AAPL_price',\n",
       "       'AAPL_Argus', 'AAPL_StarMine', 'AAPL_ColumbineCapital',\n",
       "       'AAPL_FordEquityResearch', 'AAPL_ISSEVA', 'AAPL_Jefferson',\n",
       "       'AAPL_McLeanCapital', 'AAPL_NedDavis', 'AAPL_TradingCentral',\n",
       "       'AAPL_Zacks', 'AAPL_SPValuation', 'AAPL_SPQuality',\n",
       "       'AAPL_SPGrowthStability', 'AAPL_SPFinancialHealth',\n",
       "       'AAPL_ThomsonReutersVerus', 'AAPL_ThomsonReutersIBES', 'AAPL_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def split_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next it uses the method `split_perc` to split the data on a given train, test, and val split %s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.482616Z",
     "start_time": "2021-01-15T06:53:27.468617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method split_perc in module modeling.create:\n",
      "\n",
      "split_perc(df, test_split=0.3, val_split=0.05) method of builtins.type instance\n",
      "    Splits a dataframe into train, test, and val\n",
      "    if val_split is > 0.\n",
      "    \n",
      "    Parameters\n",
      "    ----------------------------------------\n",
      "    test_split = 0.3 (float 0-1)\n",
      "        - the percentage of data to split as test\n",
      "    \n",
      "    val_split = .05 (float 0-1)\n",
      "        - the percentage of data to split as val\n",
      "    \n",
      "    Returns\n",
      "    ----------------------------------------\n",
      "    train\n",
      "        - first portion of the data, % size of\n",
      "        1 - (test_split + val_split)\n",
      "    \n",
      "    test\n",
      "        - last portion of the data, % size of\n",
      "        test_split\n",
      "    \n",
      "    val if val split > 0\n",
      "        - middle portion of the data, % size of\n",
      "        val_split\n",
      "    \n",
      "    Example Usage\n",
      "    ----------------------------------------\n",
      "    >>> import pandas as pd\n",
      "    >>> df = pd.DataFrame({\n",
      "    >>>     'apple': [1, 2, 3, 4, 5, 6],\n",
      "    >>>     'orange': [1, 2, 3, 4, 5, 6]\n",
      "    >>> })\n",
      "    >>> train, test = NetworkCreator.split_perc(\n",
      "    ...                 df, val_split=0)\n",
      "    >>> print(train)\n",
      "    >>> print(test)\n",
      "    # train\n",
      "    ...      apple  orange\n",
      "    ... 0      1       1\n",
      "    ... 1      2       2\n",
      "    ... 2      3       3\n",
      "    ... 3      4       4\n",
      "    # test\n",
      "    ...      apple  orange\n",
      "    ... 4      5       5\n",
      "    ... 5      6       6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(creator.split_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    @classmethod\n",
    "    def split_perc(cls, df, test_split=.3, val_split=.05):\n",
    "        if val_split:\n",
    "\n",
    "            total_split = test_split + val_split\n",
    "            train, test_val = train_test_split(\n",
    "                df, test_size=total_split, shuffle=False)\n",
    "\n",
    "            real_split = val_split/test_split\n",
    "            val, test = train_test_split(\n",
    "                test_val, train_size=real_split, shuffle=False)\n",
    "\n",
    "            return train, val, test\n",
    "\n",
    "        else:\n",
    "            train, test = train_test_split(\n",
    "                df, test_size=test_split, shuffle=False)\n",
    "\n",
    "            return train, test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> split_perc uses sklearn's train_test_split to do the actual splitting of the data.\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "> Now we should have a train, test, and val df that correspond to the default percentages.  (30% and 5%, test and val respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.497642Z",
     "start_time": "2021-01-15T06:53:27.483616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3, 0.05)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.test_split, creator.val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.513640Z",
     "start_time": "2021-01-15T06:53:27.498642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Expected: 231.4, Actual: 231\n",
      "Test\n",
      "Expected: 106.8, Actual: 105\n",
      "Validation\n",
      "Expected: 17.8, Actual: 20\n"
     ]
    }
   ],
   "source": [
    "original_length = len(creator.df)\n",
    "\n",
    "train_length = original_length * (1 - (creator.test_split + creator.val_split))\n",
    "\n",
    "test_length = original_length * creator.test_split\n",
    "\n",
    "val_length = original_length * creator.val_split\n",
    "\n",
    "print(\"Train\")\n",
    "print(f\"Expected: {train_length}, Actual: {len(creator.df_train)}\")\n",
    "\n",
    "print(\"Test\")\n",
    "print(f\"Expected: {test_length}, Actual: {len(creator.df_test)}\")\n",
    "\n",
    "print(\"Validation\")\n",
    "print(f\"Expected: {val_length}, Actual: {len(creator.df_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.529642Z",
     "start_time": "2021-01-15T06:53:27.514642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 356.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_length, train_length + test_length + val_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Close enough as some rounding had to take place.  Now let's take a look at the given indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.545640Z",
     "start_time": "2021-01-15T06:53:27.530641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-08-09', '2019-08-12', '2019-08-13', '2019-08-14',\n",
       "               '2019-08-15', '2019-08-16', '2019-08-19', '2019-08-20',\n",
       "               '2019-08-21', '2019-08-22',\n",
       "               ...\n",
       "               '2020-06-16', '2020-06-17', '2020-06-18', '2020-06-19',\n",
       "               '2020-06-22', '2020-06-26', '2020-06-29', '2020-06-30',\n",
       "               '2020-07-01', '2020-07-02'],\n",
       "              dtype='datetime64[ns]', name='date', length=231, freq=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.df_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.561640Z",
     "start_time": "2021-01-15T06:53:27.546641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-07-31', '2020-08-03', '2020-08-04', '2020-08-05',\n",
       "               '2020-08-06', '2020-08-07', '2020-08-10', '2020-08-11',\n",
       "               '2020-08-12', '2020-08-13',\n",
       "               ...\n",
       "               '2020-12-11', '2020-12-14', '2020-12-15', '2020-12-16',\n",
       "               '2020-12-17', '2020-12-18', '2020-12-21', '2020-12-22',\n",
       "               '2020-12-23', '2020-12-24'],\n",
       "              dtype='datetime64[ns]', name='date', length=105, freq=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.df_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.577642Z",
     "start_time": "2021-01-15T06:53:27.562642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-07-03', '2020-07-06', '2020-07-07', '2020-07-08',\n",
       "               '2020-07-09', '2020-07-10', '2020-07-13', '2020-07-14',\n",
       "               '2020-07-15', '2020-07-16', '2020-07-17', '2020-07-20',\n",
       "               '2020-07-21', '2020-07-22', '2020-07-23', '2020-07-24',\n",
       "               '2020-07-27', '2020-07-28', '2020-07-29', '2020-07-30'],\n",
       "              dtype='datetime64[ns]', name='date', freq=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.df_val.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's plot the indexes to see them in color, and where they stand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.593640Z",
     "start_time": "2021-01-15T06:53:27.578644Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_points(df):\n",
    "    X_line = np.ones(len(df))\n",
    "    return pd.DataFrame(X_line, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.769641Z",
     "start_time": "2021-01-15T06:53:27.594641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b6b0c25088>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,3))\n",
    "\n",
    "kwds = dict(ax=ax, linewidth=10)\n",
    "\n",
    "create_points(creator.df_train).plot(**kwds)\n",
    "create_points(creator.df_test).plot(**kwds)\n",
    "create_points(creator.df_val).plot(**kwds)\n",
    "\n",
    "plt.legend(['train', 'test', 'val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  The data lines up,  onto the next method!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def split_and_scale_dataframes\n",
    "> Not to be confused with the val splitting of dataframes this method is splitting the data into X and y dataframes before scaling it.  You'll see shortly why this is not split into two separate functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.785643Z",
     "start_time": "2021-01-15T06:53:27.770642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method split_and_scale_dataframes in module modeling.create:\n",
      "\n",
      "split_and_scale_dataframes() method of modeling.create.NetworkCreator instance\n",
      "    Scales and splits the data into X and y of each\n",
      "    train, test, and val.\n",
      "    \n",
      "    Creates X and/or y scalers for inverse reference\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(creator.split_and_scale_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def split_and_scale_dataframes(self):\n",
    "\n",
    "        # If there is one target\n",
    "        if len(self.y_cols) == 1:\n",
    "\n",
    "            # Define scaler\n",
    "            self.X_scaler = MinMaxScaler()\n",
    "\n",
    "            # Define y_col_idx\n",
    "            self.y_col_idx = self.column_indices[self.y_cols[0]]\n",
    "\n",
    "            # Scale data\n",
    "            self.df_scaled = self.X_scaler.fit_transform(self.df)\n",
    "\n",
    "            # Execution saver\n",
    "            if self.tuning:\n",
    "                self.X = self.df_scaled[:, :self.y_col_idx].copy()\n",
    "                self.y = self.df_scaled[:, self.y_col_idx].copy()\n",
    "                return 1\n",
    "\n",
    "            self.df_train_scaled = self.X_scaler.transform(self.df_train)\n",
    "            self.df_test_scaled = self.X_scaler.transform(self.df_test)\n",
    "            if self.val_split:\n",
    "                self.df_val_scaled = self.X_scaler.transform(self.df_val)\n",
    "\n",
    "            # Split data\n",
    "            self.X = self.df_scaled[:, :self.y_col_idx].copy()\n",
    "            self.y = self.df_scaled[:, self.y_col_idx].copy()\n",
    "            self.X_train = self.df_train_scaled[:, :self.y_col_idx].copy()\n",
    "            self.y_train = self.df_train_scaled[:, self.y_col_idx].copy()\n",
    "            self.X_test = self.df_test_scaled[:, :self.y_col_idx].copy()\n",
    "            self.y_test = self.df_test_scaled[:, self.y_col_idx].copy()\n",
    "            if self.val_split:\n",
    "                self.X_val = self.df_val_scaled[:, :self.y_col_idx].copy()\n",
    "                self.y_val = self.df_val_scaled[:, self.y_col_idx].copy()\n",
    "\n",
    "        elif self.X_cols != self.y_cols:  # Accounting for another scaler\n",
    "\n",
    "            # Split df by X and y cols\n",
    "            self.X_df = self.df[self.X_cols]\n",
    "            self.y_df = self.df[self.y_cols]\n",
    "\n",
    "            # Tuning has it's own train test split\n",
    "            if self.tuning:\n",
    "                self.X_scaler = MinMaxScaler()\n",
    "                self.y_scaler = MinMaxScaler()\n",
    "                self.X = self.X_scaler.fit_transform(self.X_df)\n",
    "                self.y = self.y_scaler.fit_transform(self.y_df)\n",
    "                return 1\n",
    "\n",
    "            self.X_df_train = self.df_train[self.X_cols]\n",
    "            self.y_df_train = self.df_train[self.y_cols]\n",
    "\n",
    "            self.X_df_test = self.df_test[self.X_cols]\n",
    "            self.y_df_test = self.df_test[self.y_cols]\n",
    "\n",
    "            if self.val_split:\n",
    "                self.X_df_val = self.df_val[self.X_cols]\n",
    "                self.y_df_val = self.df_val[self.y_cols]\n",
    "\n",
    "            # Define scalers\n",
    "            self.X_scaler = MinMaxScaler()\n",
    "            self.y_scaler = MinMaxScaler()\n",
    "\n",
    "            # Scale data\n",
    "            self.X = self.X_scaler.fit_transform(self.X_df)\n",
    "            self.y = self.y_scaler.fit_transform(self.y_df)\n",
    "\n",
    "            self.X_train = self.X_scaler.transform(self.X_df_train)\n",
    "            self.y_train = self.y_scaler.transform(self.y_df_train)\n",
    "\n",
    "            self.X_test = self.X_scaler.transform(self.X_df_test)\n",
    "            self.y_test = self.y_scaler.transform(self.y_df_test)\n",
    "\n",
    "            if self.val_split:\n",
    "                self.X_val = self.X_scaler.transform(self.X_df_val)\n",
    "                self.y_val = self.y_scaler.transform(self.y_df_val)\n",
    "\n",
    "        else:  # If X and y are the same i.e predicting self with self\n",
    "\n",
    "            # Define scaler, y is 0 because it is not used\n",
    "            self.X_scaler = MinMaxScaler()\n",
    "            self.y_scaler = 0\n",
    "\n",
    "            # Scale data\n",
    "            self.df_scaled = self.X_scaler.fit_transform(self.df)\n",
    "            self.df_train_scaled = self.X_scaler.transform(self.df_train)\n",
    "            self.df_test_scaled = self.X_scaler.transform(self.df_test)\n",
    "            if self.val_split:\n",
    "                self.df_val_scaled = self.X_scaler.transform(self.df_val)\n",
    "\n",
    "            # Split data\n",
    "            self.X = self.df_scaled.copy()\n",
    "            self.y = self.df_scaled.copy()\n",
    "\n",
    "            self.X_train = self.df_train_scaled.copy()\n",
    "            self.y_train = self.df_train_scaled.copy()\n",
    "\n",
    "            self.X_test = self.df_test_scaled.copy()\n",
    "            self.y_test = self.df_test_scaled.copy()\n",
    "\n",
    "            if self.val_split:\n",
    "                self.X_val = self.df_val_scaled.copy()\n",
    "                self.y_val = self.df_val_scaled.copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is quite a long function, but if you break it down it's actually quite simple.  Since we have one target we can simple look at the first branch and ignore the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T21:13:12.576802Z",
     "start_time": "2021-01-12T21:13:12.563803Z"
    }
   },
   "source": [
    "```python\n",
    "    # If there is one target\n",
    "        if len(self.y_cols) == 1:\n",
    "\n",
    "            # Define scaler\n",
    "            self.X_scaler = MinMaxScaler()\n",
    "\n",
    "            # Define y_col_idx\n",
    "            self.y_col_idx = self.column_indices[self.y_cols[0]]\n",
    "\n",
    "            # Scale data\n",
    "            self.df_scaled = self.X_scaler.fit_transform(self.df)\n",
    "\n",
    "            # Execution saver\n",
    "            if self.tuning:\n",
    "                self.X = self.df_scaled[:, :self.y_col_idx].copy()\n",
    "                self.y = self.df_scaled[:, self.y_col_idx].copy()\n",
    "                return 1\n",
    "\n",
    "            self.df_train_scaled = self.X_scaler.transform(self.df_train)\n",
    "            self.df_test_scaled = self.X_scaler.transform(self.df_test)\n",
    "            if self.val_split:\n",
    "                self.df_val_scaled = self.X_scaler.transform(self.df_val)\n",
    "\n",
    "            # Split data\n",
    "            self.X = self.df_scaled[:, :self.y_col_idx].copy()\n",
    "            self.y = self.df_scaled[:, self.y_col_idx].copy()\n",
    "            self.X_train = self.df_train_scaled[:, :self.y_col_idx].copy()\n",
    "            self.y_train = self.df_train_scaled[:, self.y_col_idx].copy()\n",
    "            self.X_test = self.df_test_scaled[:, :self.y_col_idx].copy()\n",
    "            self.y_test = self.df_test_scaled[:, self.y_col_idx].copy()\n",
    "            if self.val_split:\n",
    "                self.X_val = self.df_val_scaled[:, :self.y_col_idx].copy()\n",
    "                self.y_val = self.df_val_scaled[:, self.y_col_idx].copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We start off by defining out X_scaler to be used in transforming.  We fit_transform it on the original df so there are no high or lows unaccounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.801641Z",
     "start_time": "2021-01-15T06:53:27.787642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.X_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Our `y_col_idx` is for locating the given targets out of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.817641Z",
     "start_time": "2021-01-15T06:53:27.802642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.y_col_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.833640Z",
     "start_time": "2021-01-15T06:53:27.818641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAPL_price'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.df.columns[creator.y_col_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T21:18:18.869521Z",
     "start_time": "2021-01-12T21:18:18.852521Z"
    }
   },
   "source": [
    "> We'll ignore the if tuning for now, and simply show that inverse transforming the data equals the beginning dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.849641Z",
     "start_time": "2021-01-15T06:53:27.834642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.24172653, 0.97550075, ..., 0.5       , 0.90491803,\n",
       "        0.00136807],\n",
       "       [0.        , 0.24172653, 0.        , ..., 0.5       , 0.90491803,\n",
       "        0.        ],\n",
       "       [0.        , 0.24172653, 0.        , ..., 0.5       , 0.90491803,\n",
       "        0.02524982],\n",
       "       ...,\n",
       "       [0.57793424, 0.2569534 , 0.        , ..., 0.5       , 0.0852459 ,\n",
       "        0.48869855],\n",
       "       [0.57793424, 0.2569534 , 0.        , ..., 0.5       , 0.0852459 ,\n",
       "        0.48664644],\n",
       "       [0.57793424, 0.2569534 , 0.        , ..., 0.5       , 0.0852459 ,\n",
       "        0.48667618]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.df_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.865641Z",
     "start_time": "2021-01-15T06:53:27.850641Z"
    }
   },
   "outputs": [],
   "source": [
    "unscaled = creator.X_scaler.inverse_transform(creator.df_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.880641Z",
     "start_time": "2021-01-15T06:53:27.866642Z"
    }
   },
   "outputs": [],
   "source": [
    "unscaled_train = pd.DataFrame(\n",
    "    unscaled,\n",
    "    columns=creator.df_train.columns,\n",
    "    index=creator.df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.911641Z",
     "start_time": "2021-01-15T06:53:27.881643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL_RevenueTTM</th>\n",
       "      <th>AAPL_TotalCash</th>\n",
       "      <th>AAPL_ExDividendDate</th>\n",
       "      <th>AAPL_Dividend</th>\n",
       "      <th>AAPL_DividendYield</th>\n",
       "      <th>AAPL_PriceToBook</th>\n",
       "      <th>AAPL_PriceToSales</th>\n",
       "      <th>AAPL_EnterpriseValue</th>\n",
       "      <th>AAPL_PriceToCashFlow</th>\n",
       "      <th>AAPL_PE</th>\n",
       "      <th>...</th>\n",
       "      <th>AAPL_NedDavis</th>\n",
       "      <th>AAPL_TradingCentral</th>\n",
       "      <th>AAPL_Zacks</th>\n",
       "      <th>AAPL_SPValuation</th>\n",
       "      <th>AAPL_SPQuality</th>\n",
       "      <th>AAPL_SPGrowthStability</th>\n",
       "      <th>AAPL_SPFinancialHealth</th>\n",
       "      <th>AAPL_ThomsonReutersVerus</th>\n",
       "      <th>AAPL_ThomsonReutersIBES</th>\n",
       "      <th>AAPL_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-09</th>\n",
       "      <td>259034.0</td>\n",
       "      <td>94880.0</td>\n",
       "      <td>18117.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.51403</td>\n",
       "      <td>9.55691</td>\n",
       "      <td>3.65644</td>\n",
       "      <td>9.353597e+11</td>\n",
       "      <td>13.96616</td>\n",
       "      <td>17.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>50.2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-12</th>\n",
       "      <td>259034.0</td>\n",
       "      <td>94880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.53241</td>\n",
       "      <td>9.44229</td>\n",
       "      <td>3.61259</td>\n",
       "      <td>9.243031e+11</td>\n",
       "      <td>13.79865</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>50.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-13</th>\n",
       "      <td>259034.0</td>\n",
       "      <td>94880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.53631</td>\n",
       "      <td>9.41833</td>\n",
       "      <td>3.60342</td>\n",
       "      <td>9.219921e+11</td>\n",
       "      <td>13.76363</td>\n",
       "      <td>17.8</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>52.2425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-14</th>\n",
       "      <td>259034.0</td>\n",
       "      <td>94880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.47390</td>\n",
       "      <td>9.81718</td>\n",
       "      <td>3.75602</td>\n",
       "      <td>9.604636e+11</td>\n",
       "      <td>14.34650</td>\n",
       "      <td>17.2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>50.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-15</th>\n",
       "      <td>259034.0</td>\n",
       "      <td>94880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.51911</td>\n",
       "      <td>9.52497</td>\n",
       "      <td>3.64422</td>\n",
       "      <td>9.322783e+11</td>\n",
       "      <td>13.91948</td>\n",
       "      <td>17.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>50.4350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL_RevenueTTM  AAPL_TotalCash  AAPL_ExDividendDate  \\\n",
       "date                                                               \n",
       "2019-08-09         259034.0         94880.0              18117.0   \n",
       "2019-08-12         259034.0         94880.0                  0.0   \n",
       "2019-08-13         259034.0         94880.0                  0.0   \n",
       "2019-08-14         259034.0         94880.0                  0.0   \n",
       "2019-08-15         259034.0         94880.0                  0.0   \n",
       "\n",
       "            AAPL_Dividend  AAPL_DividendYield  AAPL_PriceToBook  \\\n",
       "date                                                              \n",
       "2019-08-09           0.77             1.51403           9.55691   \n",
       "2019-08-12           0.77             1.53241           9.44229   \n",
       "2019-08-13           0.77             1.53631           9.41833   \n",
       "2019-08-14           0.77             1.47390           9.81718   \n",
       "2019-08-15           0.77             1.51911           9.52497   \n",
       "\n",
       "            AAPL_PriceToSales  AAPL_EnterpriseValue  AAPL_PriceToCashFlow  \\\n",
       "date                                                                        \n",
       "2019-08-09            3.65644          9.353597e+11              13.96616   \n",
       "2019-08-12            3.61259          9.243031e+11              13.79865   \n",
       "2019-08-13            3.60342          9.219921e+11              13.76363   \n",
       "2019-08-14            3.75602          9.604636e+11              14.34650   \n",
       "2019-08-15            3.64422          9.322783e+11              13.91948   \n",
       "\n",
       "            AAPL_PE  ...  AAPL_NedDavis  AAPL_TradingCentral  AAPL_Zacks  \\\n",
       "date                 ...                                                   \n",
       "2019-08-09     17.1  ...            3.0                  3.0         3.0   \n",
       "2019-08-12     17.0  ...            3.0                  3.0         3.0   \n",
       "2019-08-13     17.8  ...            3.0                  3.0         3.0   \n",
       "2019-08-14     17.2  ...            3.0                  3.0         3.0   \n",
       "2019-08-15     17.1  ...            3.0                  3.0         3.0   \n",
       "\n",
       "            AAPL_SPValuation  AAPL_SPQuality  AAPL_SPGrowthStability  \\\n",
       "date                                                                   \n",
       "2019-08-09              87.0            93.0                    14.0   \n",
       "2019-08-12              87.0            93.0                    14.0   \n",
       "2019-08-13              87.0            93.0                    14.0   \n",
       "2019-08-14              87.0            93.0                    14.0   \n",
       "2019-08-15              87.0            93.0                    14.0   \n",
       "\n",
       "            AAPL_SPFinancialHealth  AAPL_ThomsonReutersVerus  \\\n",
       "date                                                           \n",
       "2019-08-09                    73.0                       3.0   \n",
       "2019-08-12                    73.0                       3.0   \n",
       "2019-08-13                    73.0                       3.0   \n",
       "2019-08-14                    73.0                       3.0   \n",
       "2019-08-15                    73.0                       3.0   \n",
       "\n",
       "            AAPL_ThomsonReutersIBES  AAPL_price  \n",
       "date                                             \n",
       "2019-08-09                     2.25     50.2350  \n",
       "2019-08-12                     2.25     50.1200  \n",
       "2019-08-13                     2.25     52.2425  \n",
       "2019-08-14                     2.25     50.6875  \n",
       "2019-08-15                     2.25     50.4350  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.943640Z",
     "start_time": "2021-01-15T06:53:27.912643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL_RevenueTTM</th>\n",
       "      <th>AAPL_TotalCash</th>\n",
       "      <th>AAPL_ExDividendDate</th>\n",
       "      <th>AAPL_Dividend</th>\n",
       "      <th>AAPL_DividendYield</th>\n",
       "      <th>AAPL_PriceToBook</th>\n",
       "      <th>AAPL_PriceToSales</th>\n",
       "      <th>AAPL_EnterpriseValue</th>\n",
       "      <th>AAPL_PriceToCashFlow</th>\n",
       "      <th>AAPL_PE</th>\n",
       "      <th>...</th>\n",
       "      <th>AAPL_NedDavis</th>\n",
       "      <th>AAPL_TradingCentral</th>\n",
       "      <th>AAPL_Zacks</th>\n",
       "      <th>AAPL_SPValuation</th>\n",
       "      <th>AAPL_SPQuality</th>\n",
       "      <th>AAPL_SPGrowthStability</th>\n",
       "      <th>AAPL_SPFinancialHealth</th>\n",
       "      <th>AAPL_ThomsonReutersVerus</th>\n",
       "      <th>AAPL_ThomsonReutersIBES</th>\n",
       "      <th>AAPL_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-09</th>\n",
       "      <td>259034.0</td>\n",
       "      <td>94880.0</td>\n",
       "      <td>18117</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.51403</td>\n",
       "      <td>9.55691</td>\n",
       "      <td>3.65644</td>\n",
       "      <td>9.353597e+11</td>\n",
       "      <td>13.96616</td>\n",
       "      <td>17.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>50.2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-12</th>\n",
       "      <td>259034.0</td>\n",
       "      <td>94880.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.53241</td>\n",
       "      <td>9.44229</td>\n",
       "      <td>3.61259</td>\n",
       "      <td>9.243031e+11</td>\n",
       "      <td>13.79865</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>50.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-13</th>\n",
       "      <td>259034.0</td>\n",
       "      <td>94880.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.53631</td>\n",
       "      <td>9.41833</td>\n",
       "      <td>3.60342</td>\n",
       "      <td>9.219921e+11</td>\n",
       "      <td>13.76363</td>\n",
       "      <td>17.8</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>52.2425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-14</th>\n",
       "      <td>259034.0</td>\n",
       "      <td>94880.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.47390</td>\n",
       "      <td>9.81718</td>\n",
       "      <td>3.75602</td>\n",
       "      <td>9.604636e+11</td>\n",
       "      <td>14.34650</td>\n",
       "      <td>17.2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>50.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-15</th>\n",
       "      <td>259034.0</td>\n",
       "      <td>94880.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.51911</td>\n",
       "      <td>9.52497</td>\n",
       "      <td>3.64422</td>\n",
       "      <td>9.322783e+11</td>\n",
       "      <td>13.91948</td>\n",
       "      <td>17.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>50.4350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL_RevenueTTM  AAPL_TotalCash  AAPL_ExDividendDate  \\\n",
       "date                                                               \n",
       "2019-08-09         259034.0         94880.0                18117   \n",
       "2019-08-12         259034.0         94880.0                    0   \n",
       "2019-08-13         259034.0         94880.0                    0   \n",
       "2019-08-14         259034.0         94880.0                    0   \n",
       "2019-08-15         259034.0         94880.0                    0   \n",
       "\n",
       "            AAPL_Dividend  AAPL_DividendYield  AAPL_PriceToBook  \\\n",
       "date                                                              \n",
       "2019-08-09           0.77             1.51403           9.55691   \n",
       "2019-08-12           0.77             1.53241           9.44229   \n",
       "2019-08-13           0.77             1.53631           9.41833   \n",
       "2019-08-14           0.77             1.47390           9.81718   \n",
       "2019-08-15           0.77             1.51911           9.52497   \n",
       "\n",
       "            AAPL_PriceToSales  AAPL_EnterpriseValue  AAPL_PriceToCashFlow  \\\n",
       "date                                                                        \n",
       "2019-08-09            3.65644          9.353597e+11              13.96616   \n",
       "2019-08-12            3.61259          9.243031e+11              13.79865   \n",
       "2019-08-13            3.60342          9.219921e+11              13.76363   \n",
       "2019-08-14            3.75602          9.604636e+11              14.34650   \n",
       "2019-08-15            3.64422          9.322783e+11              13.91948   \n",
       "\n",
       "            AAPL_PE  ...  AAPL_NedDavis  AAPL_TradingCentral  AAPL_Zacks  \\\n",
       "date                 ...                                                   \n",
       "2019-08-09     17.1  ...            3.0                    3           3   \n",
       "2019-08-12     17.0  ...            3.0                    3           3   \n",
       "2019-08-13     17.8  ...            3.0                    3           3   \n",
       "2019-08-14     17.2  ...            3.0                    3           3   \n",
       "2019-08-15     17.1  ...            3.0                    3           3   \n",
       "\n",
       "            AAPL_SPValuation  AAPL_SPQuality  AAPL_SPGrowthStability  \\\n",
       "date                                                                   \n",
       "2019-08-09              87.0            93.0                    14.0   \n",
       "2019-08-12              87.0            93.0                    14.0   \n",
       "2019-08-13              87.0            93.0                    14.0   \n",
       "2019-08-14              87.0            93.0                    14.0   \n",
       "2019-08-15              87.0            93.0                    14.0   \n",
       "\n",
       "            AAPL_SPFinancialHealth  AAPL_ThomsonReutersVerus  \\\n",
       "date                                                           \n",
       "2019-08-09                    73.0                       3.0   \n",
       "2019-08-12                    73.0                       3.0   \n",
       "2019-08-13                    73.0                       3.0   \n",
       "2019-08-14                    73.0                       3.0   \n",
       "2019-08-15                    73.0                       3.0   \n",
       "\n",
       "            AAPL_ThomsonReutersIBES  AAPL_price  \n",
       "date                                             \n",
       "2019-08-09                     2.25     50.2350  \n",
       "2019-08-12                     2.25     50.1200  \n",
       "2019-08-13                     2.25     52.2425  \n",
       "2019-08-14                     2.25     50.6875  \n",
       "2019-08-15                     2.25     50.4350  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.975640Z",
     "start_time": "2021-01-15T06:53:27.944643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL_RevenueTTM</th>\n",
       "      <th>AAPL_TotalCash</th>\n",
       "      <th>AAPL_ExDividendDate</th>\n",
       "      <th>AAPL_Dividend</th>\n",
       "      <th>AAPL_DividendYield</th>\n",
       "      <th>AAPL_PriceToBook</th>\n",
       "      <th>AAPL_PriceToSales</th>\n",
       "      <th>AAPL_EnterpriseValue</th>\n",
       "      <th>AAPL_PriceToCashFlow</th>\n",
       "      <th>AAPL_PE</th>\n",
       "      <th>...</th>\n",
       "      <th>AAPL_NedDavis</th>\n",
       "      <th>AAPL_TradingCentral</th>\n",
       "      <th>AAPL_Zacks</th>\n",
       "      <th>AAPL_SPValuation</th>\n",
       "      <th>AAPL_SPQuality</th>\n",
       "      <th>AAPL_SPGrowthStability</th>\n",
       "      <th>AAPL_SPFinancialHealth</th>\n",
       "      <th>AAPL_ThomsonReutersVerus</th>\n",
       "      <th>AAPL_ThomsonReutersIBES</th>\n",
       "      <th>AAPL_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-09</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-12</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-13</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-14</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-15</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL_RevenueTTM  AAPL_TotalCash  AAPL_ExDividendDate  \\\n",
       "date                                                               \n",
       "2019-08-09             True           False                False   \n",
       "2019-08-12             True           False                False   \n",
       "2019-08-13             True           False                False   \n",
       "2019-08-14             True           False                False   \n",
       "2019-08-15             True           False                False   \n",
       "\n",
       "            AAPL_Dividend  AAPL_DividendYield  AAPL_PriceToBook  \\\n",
       "date                                                              \n",
       "2019-08-09          False               False             False   \n",
       "2019-08-12          False               False             False   \n",
       "2019-08-13          False               False             False   \n",
       "2019-08-14          False               False             False   \n",
       "2019-08-15          False               False             False   \n",
       "\n",
       "            AAPL_PriceToSales  AAPL_EnterpriseValue  AAPL_PriceToCashFlow  \\\n",
       "date                                                                        \n",
       "2019-08-09               True                 False                  True   \n",
       "2019-08-12              False                 False                 False   \n",
       "2019-08-13              False                  True                 False   \n",
       "2019-08-14              False                  True                 False   \n",
       "2019-08-15              False                 False                 False   \n",
       "\n",
       "            AAPL_PE  ...  AAPL_NedDavis  AAPL_TradingCentral  AAPL_Zacks  \\\n",
       "date                 ...                                                   \n",
       "2019-08-09    False  ...          False                False       False   \n",
       "2019-08-12    False  ...          False                False       False   \n",
       "2019-08-13    False  ...          False                False       False   \n",
       "2019-08-14    False  ...          False                False       False   \n",
       "2019-08-15    False  ...          False                False       False   \n",
       "\n",
       "            AAPL_SPValuation  AAPL_SPQuality  AAPL_SPGrowthStability  \\\n",
       "date                                                                   \n",
       "2019-08-09             False           False                   False   \n",
       "2019-08-12             False           False                   False   \n",
       "2019-08-13             False           False                   False   \n",
       "2019-08-14             False           False                   False   \n",
       "2019-08-15             False           False                   False   \n",
       "\n",
       "            AAPL_SPFinancialHealth  AAPL_ThomsonReutersVerus  \\\n",
       "date                                                           \n",
       "2019-08-09                   False                     False   \n",
       "2019-08-12                   False                     False   \n",
       "2019-08-13                   False                     False   \n",
       "2019-08-14                   False                     False   \n",
       "2019-08-15                   False                     False   \n",
       "\n",
       "            AAPL_ThomsonReutersIBES  AAPL_price  \n",
       "date                                             \n",
       "2019-08-09                    False        True  \n",
       "2019-08-12                    False       False  \n",
       "2019-08-13                    False        True  \n",
       "2019-08-14                    False       False  \n",
       "2019-08-15                    False        True  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unscaled_train != creator.df_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:27.991640Z",
     "start_time": "2021-01-15T06:53:27.976641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259033.99999999997"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_train['AAPL_RevenueTTM'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:28.006640Z",
     "start_time": "2021-01-15T06:53:27.992642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259034.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.df_train['AAPL_RevenueTTM'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T21:23:17.188770Z",
     "start_time": "2021-01-12T21:23:17.172769Z"
    }
   },
   "source": [
    ">  You can see the differences is a rounding error. Let's try and sum the differences to see how miniscule it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:28.021641Z",
     "start_time": "2021-01-15T06:53:28.007641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0017089826584495912"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(creator.df_train - unscaled_train).sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def reshape_data\n",
    "> reshape data is for reshaping the data in a way the time series generator can handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:28.037641Z",
     "start_time": "2021-01-15T06:53:28.021641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method reshape_data in module modeling.create:\n",
      "\n",
      "reshape_data() method of modeling.create.NetworkCreator instance\n",
      "    Reshapes the data based on \n",
      "      - length of X/y\n",
      "      - X/y number of features\n",
      "    reshape(length, n_features)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(creator.reshape_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def reshape_data(self):\n",
    "        \"\"\"\n",
    "        Reshapes the data based on \n",
    "          - length of X/y\n",
    "          - X/y number of features\n",
    "        reshape(length, n_features)\n",
    "        \"\"\"\n",
    "        # Get n_features\n",
    "        self.X_n_features = self.X.shape[1]\n",
    "\n",
    "        if len(self.y_cols) == 1:\n",
    "            self.y_n_features = 1\n",
    "        else:\n",
    "            self.y_n_features = self.y.shape[1]\n",
    "\n",
    "        # Reshape data\n",
    "        #   Execution saver\n",
    "        if self.tuning:\n",
    "            self.X_reshaped = self.X.reshape((len(self.X),\n",
    "                                             self.X_n_features))\n",
    "            self.y_reshaped = self.y.reshape((len(self.y),\n",
    "                                             self.y_n_features))\n",
    "            return 1\n",
    "\n",
    "        self.X_train_reshaped = self.X_train.reshape((len(self.X_train),\n",
    "                                                      self.X_n_features))\n",
    "        self.y_train_reshaped = self.y_train.reshape((len(self.y_train),\n",
    "                                                      self.y_n_features))\n",
    "\n",
    "        self.X_test_reshaped = self.X_test.reshape((len(self.X_test),\n",
    "                                                    self.X_n_features))\n",
    "        self.y_test_reshaped = self.y_test.reshape((len(self.y_test),\n",
    "                                                    self.y_n_features))\n",
    "\n",
    "        if self.val_split:\n",
    "            self.X_val_reshaped = self.X_val.reshape((len(self.X_val),\n",
    "                                                      self.X_n_features))\n",
    "            self.y_val_reshaped = self.y_val.reshape((len(self.y_val),\n",
    "                                                      self.y_n_features))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:28.053640Z",
     "start_time": "2021-01-15T06:53:28.038642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:28.069641Z",
     "start_time": "2021-01-15T06:53:28.054642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.y_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:28.085641Z",
     "start_time": "2021-01-15T06:53:28.070641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 35)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:28.101640Z",
     "start_time": "2021-01-15T06:53:28.086641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 35)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.X_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can see that X_train doesn't change, but y_train does.  If there was one feature it would do the same for X_train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def create_TS_generators\n",
    "> Onto the creating of the time series generators.  Originally we set n_days to one so we will show what that did, and then show what happens when we change n_days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:28.117640Z",
     "start_time": "2021-01-15T06:53:28.102641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create_TS_generators in module modeling.create:\n",
      "\n",
      "create_TS_generators(n_days) method of modeling.create.NetworkCreator instance\n",
      "    Creates the data generators.\n",
      "    \n",
      "    TS = tensorflow.keras.preprocessing.sequence.TimeseriesGenerator\n",
      "        - Time series generator for feeding into the model\n",
      "        splits on data and targets.\n",
      "    \n",
      "    Example\n",
      "    ----------------------------------------\n",
      "    data =\n",
      "          apple  orange  banana\n",
      "    date\n",
      "      1     1      2       2\n",
      "      2     4      2       3\n",
      "      3     3      3       6\n",
      "    \n",
      "    data = [apple, orange, banana]\n",
      "    target = banana\n",
      "    target is banana the following day, predicted\n",
      "    with n_days before\n",
      "    \n",
      "    TS[n_days = 1]:\n",
      "    Here banana on day two is predicted with all of the the data\n",
      "    from day one, then day three is predicted from all of the data\n",
      "    from day two\n",
      "        data:\n",
      "            [[1, 2, 2],\n",
      "            [4, 2, 3]]\n",
      "        target:\n",
      "            [[3],\n",
      "            [6]]\n",
      "    TS[n_days = 2]:\n",
      "    Here banana on day three is predicted with all of the data\n",
      "    from all of the columns on day 1 and 2\n",
      "        data:\n",
      "            [[1, 2, 2\n",
      "              4, 2, 3]]\n",
      "        target:\n",
      "            [[6]]\n",
      "    \n",
      "    Parameters\n",
      "    ----------------------------------------\n",
      "    n_days{int}::\n",
      "        Number of days to predict next with\n",
      "    \n",
      "    Returns\n",
      "    ----------------------------------------\n",
      "    data[TS]\n",
      "    train[TS]\n",
      "    test[TS]\n",
      "    val[TS] if val_split > 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(creator.create_TS_generators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def create_TS_generators(self, n_days):\n",
    "        if self.tuning:\n",
    "            data = sequence.TimeseriesGenerator(\n",
    "                self.X_reshaped,\n",
    "                self.y_reshaped,\n",
    "                length=self.n_input\n",
    "            )\n",
    "            return data\n",
    "\n",
    "        train = sequence.TimeseriesGenerator(\n",
    "            self.X_train_reshaped,\n",
    "            self.y_train_reshaped,\n",
    "            length=self.n_input\n",
    "            )\n",
    "\n",
    "        test = sequence.TimeseriesGenerator(\n",
    "            self.X_test_reshaped,\n",
    "            self.y_test_reshaped,\n",
    "            length=self.n_input\n",
    "            )\n",
    "\n",
    "        if self.val_split:\n",
    "            val = sequence.TimeseriesGenerator(\n",
    "                self.X_val_reshaped,\n",
    "                self.y_val_reshaped,\n",
    "                length=self.n_input\n",
    "                )\n",
    "            return train, test, val\n",
    "\n",
    "        return train, test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We'll ignore the tuning for now,  but let's call the function and get each of the time series generators to analyze what is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:55:29.482409Z",
     "start_time": "2021-01-15T06:55:29.467347Z"
    }
   },
   "outputs": [],
   "source": [
    "train_gen, test_gen, val_gen = creator.create_TS_generators(n_days=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T22:07:09.902486Z",
     "start_time": "2021-01-12T22:07:09.887485Z"
    }
   },
   "source": [
    ">for a generator we can pull out X and y to see the shape. The TimeSeriesGenerator works by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:55:30.430847Z",
     "start_time": "2021-01-15T06:55:30.419279Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = train_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:55:30.827689Z",
     "start_time": "2021-01-15T06:55:30.823690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.24172653, 0.97550075, 0.91869919, 0.97591846,\n",
       "        0.0803882 , 0.2546881 , 0.21056232, 0.24114823, 0.23624595,\n",
       "        0.        , 0.        , 0.        , 0.04671975, 0.47887411,\n",
       "        0.04694591, 0.20944665, 0.00826982, 0.00136807, 0.        ,\n",
       "        0.25      , 0.        , 1.        , 0.92982456, 1.        ,\n",
       "        1.        , 0.        , 1.        , 0.25      , 1.        ,\n",
       "        0.66666667, 0.02439024, 0.94736842, 0.5       , 0.90491803],\n",
       "       [0.        , 0.24172653, 0.        , 0.91869919, 0.99578465,\n",
       "        0.07612229, 0.24800007, 0.20429657, 0.23462178, 0.23300971,\n",
       "        0.        , 0.        , 0.        , 0.03887501, 0.46478025,\n",
       "        0.03920602, 0.20309792, 0.00806834, 0.        , 0.        ,\n",
       "        0.25      , 0.        , 1.        , 0.92982456, 1.        ,\n",
       "        1.        , 0.        , 1.        , 0.25      , 1.        ,\n",
       "        0.66666667, 0.02439024, 0.94736842, 0.5       , 0.90491803],\n",
       "       [0.        , 0.24172653, 0.        , 0.91869919, 1.        ,\n",
       "        0.07523055, 0.24660146, 0.20298692, 0.23325735, 0.25889968,\n",
       "        0.        , 0.        , 0.        , 0.03740132, 0.46183438,\n",
       "        0.03771977, 0.19762153, 0.007995  , 0.02524982, 0.        ,\n",
       "        0.25      , 0.        , 1.        , 0.92982456, 1.        ,\n",
       "        1.        , 0.        , 1.        , 0.25      , 1.        ,\n",
       "        0.66666667, 0.02439024, 0.94736842, 0.5       , 0.90491803]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can see X is three days for one price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:56:02.741120Z",
     "start_time": "2021-01-15T06:56:02.735120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00675113])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:53:28.165641Z",
     "start_time": "2021-01-15T06:53:28.150642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 3, 35), (128, 1))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> X as `(128, 1, 35)` shows 128 periods of 3 days consisting of 35 features, and y being `(128, 1)` shows 128 periods of 1 feature.  Now let's look at using one day to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:56:20.535486Z",
     "start_time": "2021-01-15T06:56:20.521486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 1, 35), (128, 1))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen, test_gen, val_gen = creator.create_TS_generators(n_days=1)\n",
    "X, y = train_gen[0]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:56:24.587392Z",
     "start_time": "2021-01-15T06:56:24.571392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.24172653, 0.97550075, 0.91869919, 0.97591846,\n",
       "        0.0803882 , 0.2546881 , 0.21056232, 0.24114823, 0.23624595,\n",
       "        0.        , 0.        , 0.        , 0.04671975, 0.47887411,\n",
       "        0.04694591, 0.20944665, 0.00826982, 0.00136807, 0.        ,\n",
       "        0.25      , 0.        , 1.        , 0.92982456, 1.        ,\n",
       "        1.        , 0.        , 1.        , 0.25      , 1.        ,\n",
       "        0.66666667, 0.02439024, 0.94736842, 0.5       , 0.90491803]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:56:28.285397Z",
     "start_time": "2021-01-15T06:56:28.274363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  That's it for our `prepare_data` function.  The next step of our sample code is our build and fit model.  Let's check it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## def build_and_fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T06:59:34.641390Z",
     "start_time": "2021-01-15T06:59:34.623388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method build_and_fit_model in module modeling.create:\n",
      "\n",
      "build_and_fit_model(hp=None, **parameters) method of modeling.create.NetworkCreator instance\n",
      "    wrapper for build and fit model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(creator.build_and_fit_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T07:00:25.858557Z",
     "start_time": "2021-01-15T07:00:25.844557Z"
    }
   },
   "source": [
    "```python\n",
    "    def build_and_fit_model(self, hp=None, **parameters):\n",
    "        \"\"\"wrapper for build and fit model\"\"\"\n",
    "        builder = NetworkBuilder(\n",
    "            self,\n",
    "            self.n_input,\n",
    "            self.input_shape,\n",
    "            output_shape=len(self.y_cols)\n",
    "            )\n",
    "        self.model = builder.build_and_fit_model(hp, **parameters)\n",
    "        return self.model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As you can see this simply creates a `NetworkBuilder` instance, and then calls the build_and_fit_model of that instance.  Let's look at a quick sample of that.  One of the parameters we fed in was `'input_dropout_rate': 0.1,`, what does that do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#           Dropout layer\n",
    "input_dropout_rate = self.hp.Choice('input_dropout_rate',\n",
    "                                    input_dropout_rate)\n",
    "if input_dropout_rate != 0:\n",
    "    self.model.add(Dropout(input_dropout_rate))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is a small batch of code from our Builder.  If hp is being dummied (which it is)  it simple selected the given parameter, so you can ignore the hp.Choice as that is for tuning.  There are many other parameters we can change, and even tune.  Let's take a look at the documentation for builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T07:05:43.809623Z",
     "start_time": "2021-01-15T07:05:43.805623Z"
    }
   },
   "outputs": [],
   "source": [
    "from modeling.build import NetworkBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T07:05:49.478091Z",
     "start_time": "2021-01-15T07:05:49.466060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function build_and_fit_model in module modeling.build:\n",
      "\n",
      "build_and_fit_model(self, hp=None, n_days=1, input_dropout_rate=0, use_input_regularizer=0, input_regularizer_penalty=0, add_gaussian_noise=0, gaussian_noise_quotient=0, add_hidden_lstm=0, hidden_lstm_neurons=64, n_hidden_layers=1, hidden_layer_activation='relu', hidden_dropout_rate=0.3, hidden_neurons=64, use_hidden_regularizer=0, hidden_regularizer_penalty=0, optimizer='adam', use_early_stopping=False, monitor='val_loss', patience=5, batch_size=32, shuffle=False, dummy_hp=False)\n",
      "    Parameters\n",
      "    ----------------------------------------\n",
      "    hp=None,\n",
      "    dummy_hp=False(bool)::\n",
      "        - whether to use a dummy_hp or not for simply building the\n",
      "        model or tuning it.  Will return an error if the model is not\n",
      "        tuning and dummy_hp is False\n",
      "    \n",
      "    Data Params\n",
      "        ------------------------------------\n",
      "    n_days=1,\n",
      "    \n",
      "    Input Layer Params\n",
      "        ------------------------------------\n",
      "    input_neurons=64\n",
      "    input_dropout_rate=0\n",
      "    use_input_regularizer=0\n",
      "    input_regularizer_penalty=0\n",
      "    \n",
      "    Hidden Layer Params\n",
      "        ------------------------------------\n",
      "    #   Solo\n",
      "    add_gaussian_noise=0,\n",
      "    gaussian_noise_quotient=0,\n",
      "    add_hidden_lstm=0,\n",
      "    hidden_lstm_neurons=64,\n",
      "    #   Group\n",
      "    n_hidden_layers=1\n",
      "    hidden_layer_activation='relu'\n",
      "    hidden_dropout_rate=.3\n",
      "    hidden_neurons=64\n",
      "    use_hidden_regularizer=0\n",
      "    hidden_regularizer_penalty=0\n",
      "    \n",
      "    Compile Params\n",
      "        ------------------------------------\n",
      "    optimizer='adam'\n",
      "    \n",
      "    Early Stopping Params\n",
      "        ------------------------------------\n",
      "    use_early_stopping=True,\n",
      "    monitor='val_loss',\n",
      "    patience=5,\n",
      "    \n",
      "    Model Fit Params\n",
      "        ------------------------------------\n",
      "    batch_size=32,\n",
      "    shuffle=False,\n",
      "    \n",
      "    Returns\n",
      "    ----------------------------------------\n",
      "    self.model(tensorflow.keras.models.Sequential)\n",
      "    OR\n",
      "    self.model(.modeling.CustomSequantial) when tuning\n",
      "        - built using parameters\n",
      "        - fit function is functools.partial with\n",
      "          defined fit arguments already plugged\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(NetworkBuilder.build_and_fit_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Above are all of the tunable parameters for our neural network; creating a simple way to tune a given model, and use those tuned parameters to create a network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finally we call our model fit method.  Which is the keras fit function slightly modified with a partial function.  As you can see below we change the fit method to include parameters we added to it, and can still call it as we would normally call a fit function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# From our NetworkBuilder.build_and_fit_model method\n",
    "self.model.fit = partial(\n",
    "    self.model.fit,\n",
    "    callbacks=model_callbacks,\n",
    "    batch_size=self.hp.Choice('batch_size', batch_size),\n",
    "    shuffle=shuffle\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then to call the fit function as we did before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "history = creator.model.fit(\n",
    "    creator.train_data_gen,\n",
    "    validation_data=creator.val_data_gen,\n",
    "    epochs=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success shadow\"> \n",
    "    <b>Check out our other notebooks if this is where you started</b>\n",
    "    <ul>\n",
    "        <li><a href=\"./main.ipynb\">Main</a>: showcasing our entire project</li>\n",
    "        <li><a href=\"./Pull and clean data.ipynb\">Scrubbing</a>: showcasing the cleaning of our data</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
