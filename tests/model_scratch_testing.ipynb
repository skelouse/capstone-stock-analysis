{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intro\" data-toc-modified-id=\"Intro-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intro</a></span><ul class=\"toc-item\"><li><span><a href=\"#Presets\" data-toc-modified-id=\"Presets-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Presets</a></span></li><li><span><a href=\"#Style,-imports,-and-data\" data-toc-modified-id=\"Style,-imports,-and-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Style, imports, and data</a></span></li><li><span><a href=\"#GPU\" data-toc-modified-id=\"GPU-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>GPU</a></span></li></ul></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Modeling-with-Time-Series-Generator\" data-toc-modified-id=\"Modeling-with-Time-Series-Generator-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Modeling with Time Series Generator</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:10:04.295158Z",
     "start_time": "2020-12-07T09:10:04.290636Z"
    }
   },
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "IGNORE_WARN = True\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style, imports, and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:10:04.467159Z",
     "start_time": "2020-12-07T09:10:04.296161Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.titlesize']='xx-large'\n",
    "mpl.rcParams['xtick.labelsize'] = 13\n",
    "mpl.rcParams['ytick.labelsize'] = 13\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "if IGNORE_WARN:\n",
    "    warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:10:04.991158Z",
     "start_time": "2020-12-07T09:10:04.469163Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:10:07.053161Z",
     "start_time": "2020-12-07T09:10:04.993158Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:10:07.069158Z",
     "start_time": "2020-12-07T09:10:07.055158Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:10:07.513158Z",
     "start_time": "2020-12-07T09:10:07.070159Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding\n",
    "# from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:10:07.574160Z",
     "start_time": "2020-12-07T09:10:07.515158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "if USE_GPU:\n",
    "    # Enable GPU\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "    os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "\n",
    "    # Show GPU\n",
    "    print(\"Using GPU\")\n",
    "    print(tf.config.list_physical_devices('GPU'))\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Time Series Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:10:07.589160Z",
     "start_time": "2020-12-07T09:10:07.576165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orange</th>\n",
       "      <th>banana</th>\n",
       "      <th>apple</th>\n",
       "      <th>pear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      orange  banana  apple  pear\n",
       "date                             \n",
       "1          1       2      4     2\n",
       "2          5       4      2     7\n",
       "3          3       7      2     5\n",
       "4          4       4      5     4\n",
       "5          2       5      8     2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame({\n",
    "    'date': [1, 2, 3, 4, 5],\n",
    "    'orange': [1, 5, 3, 4, 2],\n",
    "    'banana': [2, 4, 7, 4, 5],\n",
    "    'apple': [4, 2, 2, 5, 8],\n",
    "    'pear': [2, 7, 5, 4, 2]\n",
    "    })\n",
    "test_df = test_df.set_index('date', drop=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:10:19.417912Z",
     "start_time": "2020-12-07T09:10:19.403911Z"
    }
   },
   "outputs": [],
   "source": [
    "def contains(sub, pri):\n",
    "    \"https://stackoverflow.com/questions/3847386/how-to-test-if-a-list-contains-another-list\" \n",
    "    M, N = len(pri), len(sub)\n",
    "    i, LAST = 0, M-N+1\n",
    "    while True:\n",
    "        try:\n",
    "            found = pri.index(sub[0], i, LAST) # find first elem in sub\n",
    "        except ValueError:\n",
    "            return False\n",
    "        if pri[found:found+N] == sub:\n",
    "            return [found, found+N-1]\n",
    "        else:\n",
    "            i = found+1\n",
    "            \n",
    "#contains(y_cols, X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:10:23.535693Z",
     "start_time": "2020-12-07T09:10:20.060919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y is in dataframe but not x\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4667\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.4467\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4435\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4358\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4334\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4172\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4186\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4014\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.3959\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.3838\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def model_network(df, model, X_cols, y_cols, n_input):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        if X_cols == y_cols:\n",
    "            print('y is the same as x')\n",
    "            df = df[X_cols]\n",
    "        elif ((contains(y_cols, X_cols)[1]\n",
    "            - contains(y_cols, X_cols)[0])\n",
    "            + 1 == len(y_cols)):\n",
    "            print(\"y is in x\")\n",
    "        else:\n",
    "            print('y is different than x')\n",
    "            select_cols = X_cols + y_cols\n",
    "            df = df[select_cols]\n",
    "    except TypeError:\n",
    "        print('y is in dataframe but not x')\n",
    "    \n",
    "    df_train = df.copy()\n",
    "    \n",
    "    # Account for another scaler\n",
    "    if X_cols is not y_cols:\n",
    "        X_df_train = df_train[X_cols]\n",
    "        y_df_train = df_train[y_cols]\n",
    "        \n",
    "        X_scaler = MinMaxScaler()\n",
    "        y_scaler = MinMaxScaler()\n",
    "        \n",
    "        X_train = X_scaler.fit_transform(X_df_train)\n",
    "        y_train = y_scaler.fit_transform(y_df_train)\n",
    "\n",
    "    \n",
    "    # If X and y are the same i.e predicting self with self\n",
    "    else:\n",
    "        X_scaler = MinMaxScaler()\n",
    "        y_scaler = 0\n",
    "        df_train_scaled = X_scaler.fit_transform(df_train)\n",
    "        X_train = df_train_scaled.copy()\n",
    "        y_train = df_train_scaled.copy()\n",
    "\n",
    "    # Reshape\n",
    "    X_n_features = X_train.shape[1]\n",
    "    y_n_features = y_train.shape[1]\n",
    "    \n",
    "    X_train_reshaped = X_train.reshape((len(X_train), X_n_features))\n",
    "    y_train_reshaped = y_train.reshape((len(y_train), y_n_features))\n",
    "    \n",
    "    train_data_gen = sequence.TimeseriesGenerator( \\\n",
    "                         X_train_reshaped,\n",
    "                         y_train_reshaped,#[:,column_indices[y_cols]],\n",
    "                         length=n_input)\n",
    "    input_shape = (X_train_reshaped.shape[0], X_train_reshaped.shape[1])\n",
    "    \n",
    "    history = model.fit(train_data_gen, epochs=10)\n",
    "    \n",
    "    \n",
    "X_cols = list(test_df.columns)\n",
    "y_cols = ['apple', 'pear']\n",
    "n_features = len(y_cols)\n",
    "n_days = 1\n",
    "split_point = 2\n",
    "input_shape = (2, len(X_cols))\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=input_shape))\n",
    "model.add(Dropout(.3))\n",
    "for i in range(1):\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(.1))\n",
    "model.add(Dense(len(y_cols)))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "\n",
    "model_network(test_df, model,  ['apple', 'banana', 'pear'], ['orange'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:10:07.745158Z",
     "start_time": "2020-12-07T09:10:04.304Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_hermes.copy()\n",
    "df_train = df.iloc[:250].copy()\n",
    "df_test = df.iloc[250:-20].copy()\n",
    "df_val = df.iloc[-20::].copy()\n",
    "\n",
    "X_df_train = df_train[X_cols]\n",
    "y_df_train = df_train[y_cols]\n",
    "X_df_test = df_test[X_cols]\n",
    "y_df_test = df_test[y_cols]\n",
    "X_df_val = df_val[X_cols]\n",
    "y_df_val = df_val[y_cols]\n",
    "print(y_df_train.shape)\n",
    "X_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "X_train = X_scaler.fit_transform(X_df_train)\n",
    "y_train = y_scaler.fit_transform(y_df_train)\n",
    "X_test = X_scaler.transform(X_df_test)\n",
    "y_test = y_scaler.transform(y_df_test)\n",
    "X_val = X_scaler.transform(X_df_val)\n",
    "y_val = y_scaler.transform(y_df_val)\n",
    "\n",
    "\n",
    "X_train = X_scaler.fit_transform(X_df_train)\n",
    "y_train = y_scaler.fit_transform(y_df_train)\n",
    "y_n_features = y_train.shape[1]\n",
    "y_n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:11:07.889148Z",
     "start_time": "2020-12-07T09:11:07.857146Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_network(df, model, X_cols, y_cols, n_input):\n",
    "    print(df.shape, len(X_cols), len(y_cols))\n",
    "    if isinstance(X_cols, str):\n",
    "        X_cols = [col for col in df.columns if X_cols in col]\n",
    "    if isinstance(y_cols, str):\n",
    "        y_cols = [col for col in df.columns if y_cols in col]\n",
    "    \n",
    "    try:\n",
    "        if X_cols == y_cols:\n",
    "            print('y is the same as x')\n",
    "            df = df[X_cols]\n",
    "        elif ((contains(y_cols, X_cols)[1]\n",
    "            - contains(y_cols, X_cols)[0])\n",
    "            + 1 == len(y_cols)):\n",
    "            print(\"y is in x\")\n",
    "        else:\n",
    "            print('y is different than x')\n",
    "            select_cols = X_cols + y_cols\n",
    "            df = df[select_cols]\n",
    "    except TypeError:\n",
    "        print('y is in dataframe but not x')\n",
    "        \n",
    "    print(\"X_cols\", len(X_cols))\n",
    "    print(\"y_cols\", len(y_cols))\n",
    "\n",
    "#     if X_cols == y_cols:\n",
    "#         print('y is the same as x')\n",
    "#         df = df[X_cols]\n",
    "#     elif contains(y_cols, X_cols)[1] - contains(y_cols, X_cols)[0] + 1 == len(y_cols):\n",
    "#         print(\"y is in x\")\n",
    "#     else:\n",
    "#         print('y is different than x')\n",
    "#         select_cols = X_cols + y_cols\n",
    "#         df = df[select_cols]\n",
    "#         display(df.columns)\n",
    "    #column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "    # Split dataframes\n",
    "    df_train = df.iloc[:250].copy()\n",
    "    df_test = df.iloc[250:-20].copy()\n",
    "    df_val = df.iloc[-20::].copy()\n",
    "\n",
    "    # Account for another scaler\n",
    "    if X_cols is not y_cols:\n",
    "        print(\"Creating y scaler\")\n",
    "        X_df_train = df_train[X_cols]\n",
    "        y_df_train = df_train[y_cols]\n",
    "        X_df_test = df_test[X_cols]\n",
    "        y_df_test = df_test[y_cols]\n",
    "        X_df_val = df_val[X_cols]\n",
    "        y_df_val = df_val[y_cols]\n",
    "\n",
    "        X_scaler = MinMaxScaler()\n",
    "        y_scaler = MinMaxScaler()\n",
    "\n",
    "        X_train = X_scaler.fit_transform(X_df_train)\n",
    "        y_train = y_scaler.fit_transform(y_df_train)\n",
    "        X_test = X_scaler.transform(X_df_test)\n",
    "        y_test = y_scaler.transform(y_df_test)\n",
    "        X_val = X_scaler.transform(X_df_val)\n",
    "        y_val = y_scaler.transform(y_df_val)\n",
    "\n",
    "    # If X and y are the same i.e predicting self with self\n",
    "    else:\n",
    "        X_scaler = MinMaxScaler()\n",
    "        y_scaler = 0\n",
    "        df_train_scaled = X_scaler.fit_transform(df_train)\n",
    "        df_test_scaled = X_scaler.transform(df_test)\n",
    "        df_val_scaled = X_scaler.transform(df_val)\n",
    "        X_train = df_train_scaled.copy()\n",
    "        y_train = df_train_scaled.copy()\n",
    "        X_test = df_test_scaled.copy()\n",
    "        y_test = df_test_scaled.copy()\n",
    "        X_val = df_val_scaled.copy()\n",
    "        y_val = df_val_scaled.copy()\n",
    "\n",
    "    # Get n_features\n",
    "    X_n_features = X_train.shape[1]\n",
    "    y_n_features = y_train.shape[1]\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    print(\"len(X_train)\", len(X_train))\n",
    "    print(\"len(y_train)\", len(y_train))\n",
    "\n",
    "    # Reshape data\n",
    "    X_train_reshaped = X_train.reshape((len(X_train), X_n_features))\n",
    "    y_train_reshaped = y_train.reshape((len(y_train), y_n_features))\n",
    "    X_test_reshaped = X_test.reshape((len(X_test), X_n_features))\n",
    "    y_test_reshaped = y_test.reshape((len(y_test), y_n_features))\n",
    "    X_val_reshaped = X_val.reshape((len(X_val), X_n_features))\n",
    "    y_val_reshaped = y_val.reshape((len(y_val), y_n_features))\n",
    "\n",
    "    # Get data generators\n",
    "    print(\"create generator\")\n",
    "    import time\n",
    "    old = time.time()\n",
    "    train_data_gen = sequence.TimeseriesGenerator( \\\n",
    "                         X_train_reshaped,\n",
    "                         y_train_reshaped,#[:,column_indices[y_cols]],\n",
    "                         length=n_input)\n",
    "    test_data_gen = sequence.TimeseriesGenerator( \\\n",
    "                        X_test_reshaped,\n",
    "                        y_test_reshaped,#[:,column_indices[y_cols]],\n",
    "                        length=n_input)\n",
    "    val_data_gen = sequence.TimeseriesGenerator( \\\n",
    "                        X_val_reshaped,\n",
    "                        y_val_reshaped,#[:,column_indices[y_cols]],\n",
    "                        length=n_input)\n",
    "    print(\"created in %ss\" % (time.time()-old))\n",
    "\n",
    "    input_shape = (X_train_reshaped.shape[0], X_train_reshaped.shape[1])\n",
    "    print(\"input_shape\", input_shape)\n",
    "    \n",
    "    print(\"X_n_features\", X_n_features)\n",
    "    print(\"y_n_features\", y_n_features)\n",
    "    # Model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', patience=25)\n",
    "    history = model.fit(train_data_gen,\n",
    "                        epochs=2000, batch_size=64,\n",
    "                        validation_data=(test_data_gen),\n",
    "                        verbose=2, shuffle=False,\n",
    "                        callbacks=[earlystopping])\n",
    "\n",
    "    # my_loss= history.history['loss']\n",
    "    # plt.plot(range(len(my_loss)),my_loss)\n",
    "\n",
    "\n",
    "    # Predictions (r2_score)\n",
    "\n",
    "    # If predicting one column for y\n",
    "    if y_scaler and (len(y_cols) == 1):\n",
    "        df_train['predicted'] = pd.DataFrame(y_scaler.inverse_transform(model.predict(train_data_gen)), columns=y_cols,\n",
    "                                            index=df_train[n_input:][y_cols].index)\n",
    "        df_test['predicted'] = pd.DataFrame(y_scaler.inverse_transform(model.predict(test_data_gen)), columns=y_cols,\n",
    "                                            index=df_test[n_input:][y_cols].index)\n",
    "        df_val['predicted'] = pd.DataFrame(y_scaler.inverse_transform(model.predict(val_data_gen)), columns=y_cols,\n",
    "                                            index=df_val[n_input:][y_cols].index)\n",
    "        cols = y_cols + ['predicted']\n",
    "        df_predict_train = df_train[cols].dropna()\n",
    "        df_predict_test = df_test[cols].dropna()\n",
    "        df_predict_val = df_val[cols].dropna()\n",
    "\n",
    "        train_r2 = r2_score(df_predict_train[y_cols], df_predict_train[['predicted']])\n",
    "        test_r2 = r2_score(df_predict_test[y_cols], df_predict_test[['predicted']])\n",
    "        val_r2 = r2_score(df_predict_val[y_cols], df_predict_val[['predicted']])\n",
    "\n",
    "        print(\"Train r2 =\", train_r2)\n",
    "        print(\"Test r2 =\", test_r2)\n",
    "        print(\"Val r2 =\", val_r2)\n",
    "\n",
    "\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(15, 6))\n",
    "        df_predict_train[cols].plot(ax=ax1)\n",
    "        df_predict_test[cols].plot(ax=ax2)\n",
    "        df_predict_val[cols].plot(ax=ax3)\n",
    "\n",
    "    # If predicting multiple columns for y\n",
    "    elif y_scaler:\n",
    "        df_predict_train = pd.DataFrame(y_scaler.inverse_transform(model.predict(train_data_gen)), columns=y_cols,\n",
    "                                            index=y_df_train[n_input:].index)\n",
    "        df_predict_test = pd.DataFrame(y_scaler.inverse_transform(model.predict(test_data_gen)), columns=y_cols,\n",
    "                                            index=y_df_test[n_input:].index)\n",
    "        df_predict_val = pd.DataFrame(y_scaler.inverse_transform(model.predict(val_data_gen)), columns=y_cols,\n",
    "                                            index=y_df_val[n_input:].index)\n",
    "\n",
    "        y_true_train = y_df_train.loc[df_predict_train.index]\n",
    "        y_true_test = y_df_test.loc[df_predict_test.index]\n",
    "        y_true_val = y_df_val.loc[df_predict_val.index]\n",
    "\n",
    "        train_r2 = r2_score(y_true_train, df_predict_train)\n",
    "        test_r2 = r2_score(y_true_test, df_predict_test)\n",
    "        val_r2 = r2_score(y_true_val, df_predict_val)\n",
    "        print(\"Train r2 =\", train_r2)\n",
    "        print(\"Test r2 =\", test_r2)\n",
    "        print(\"Val r2 =\", val_r2)\n",
    "\n",
    "    # if predicting self with self\n",
    "    else:\n",
    "        df_predict_train = pd.DataFrame(X_scaler.inverse_transform(model.predict(train_data_gen)), columns=y_cols,\n",
    "                                         index=df_train[n_input:].index)\n",
    "        df_predict_test = pd.DataFrame(X_scaler.inverse_transform(model.predict(test_data_gen)), columns=y_cols,\n",
    "                                         index=df_test[n_input:].index)\n",
    "        df_predict_val = pd.DataFrame(X_scaler.inverse_transform(model.predict(val_data_gen)), columns=y_cols,\n",
    "                                         index=df_val[n_input:].index)\n",
    "\n",
    "        y_true_train = df_train.loc[df_predict_train.index]\n",
    "        y_true_test = df_test.loc[df_predict_test.index]\n",
    "        y_true_val = df_val.loc[df_predict_val.index]\n",
    "\n",
    "        train_r2 = r2_score(y_true_train, df_predict_train)\n",
    "        test_r2 = r2_score(y_true_test, df_predict_test)\n",
    "        val_r2 = r2_score(y_true_val, df_predict_val)\n",
    "        print(\"Train r2 =\", train_r2)\n",
    "        print(\"Test r2 =\", test_r2)\n",
    "        print(\"Val r2 =\", val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:13:11.406448Z",
     "start_time": "2020-12-07T09:13:11.398450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((342, 87462), 81270, 12384)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hermes.shape, len(X_cols), len(y_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:11:09.189144Z",
     "start_time": "2020-12-07T09:11:09.179144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342, 6192)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analyst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:11:09.629185Z",
     "start_time": "2020-12-07T09:11:09.623182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 81270)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:11:55.605443Z",
     "start_time": "2020-12-07T09:11:55.598439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((342, 87462), (342, 6192))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hermes.shape, df_analyst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:11:29.430005Z",
     "start_time": "2020-12-07T09:11:29.415010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342, 93654)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:16:57.615873Z",
     "start_time": "2020-12-07T09:16:57.591487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([col for col in df_hermes.columns if 'Zacks' in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T09:18:14.618084Z",
     "start_time": "2020-12-07T09:18:07.776123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 87462) 81270 6192\n",
      "y is in dataframe but not x\n",
      "X_cols 81270\n",
      "y_cols 6192\n",
      "Creating y scaler\n",
      "(250, 6192)\n",
      "len(X_train) 250\n",
      "len(y_train) 250\n",
      "create generator\n",
      "created in 0.0s\n",
      "input_shape (250, 81270)\n",
      "X_n_features 81270\n",
      "y_n_features 6192\n",
      "Epoch 1/2000\n",
      "2/2 - 1s - loss: 0.3369 - val_loss: 0.5805\n",
      "Epoch 2/2000\n",
      "2/2 - 0s - loss: 0.3138 - val_loss: 0.5493\n",
      "Epoch 3/2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-6e03bccd2a57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mcreator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_hermes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_days\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-73cdd9d9bd15>\u001b[0m in \u001b[0;36mmodel_network\u001b[1;34m(df, model, X_cols, y_cols, n_input)\u001b[0m\n\u001b[0;32m    122\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                         callbacks=[earlystopping])\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;31m# my_loss= history.history['loss']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_hermes = pd.read_pickle(\"./data/modeling/hermes.pkl\")\n",
    "df_analyst = pd.read_pickle(\"./data/modeling/analyst.pkl\")\n",
    "#df_total = pd.concat([df_hermes, df_analyst], axis=1)\n",
    "X_cols = [col for col in df_hermes.columns if col not in df_analyst.columns]\n",
    "y_cols = [col for col in df_hermes.columns if col in df_analyst.columns]\n",
    "n_days = 4\n",
    "split_point = 250\n",
    "input_shape = (split_point, len(X_cols))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=input_shape))\n",
    "model.add(Dropout(.3))\n",
    "for i in range(1):\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(.1))\n",
    "model.add(Dense(len(y_cols)))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "creator = model_network(df_hermes, model, X_cols, y_cols, n_days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:01:09.921856Z",
     "start_time": "2020-12-05T19:01:01.866161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "len(X_train) 250\n",
      "len(y_train) 250\n",
      "create generator\n",
      "created in 0.0s\n",
      "input_shape (250, 6834)\n",
      "X_n_features 6834\n",
      "y_n_features 402\n",
      "Epoch 1/2000\n",
      "2/2 - 1s - loss: 0.4103 - val_loss: 0.5771\n",
      "Epoch 2/2000\n",
      "2/2 - 0s - loss: 0.3780 - val_loss: 0.5510\n",
      "Epoch 3/2000\n",
      "2/2 - 0s - loss: 0.3537 - val_loss: 0.5132\n",
      "Epoch 4/2000\n",
      "2/2 - 0s - loss: 0.3278 - val_loss: 0.4819\n",
      "Epoch 5/2000\n",
      "2/2 - 0s - loss: 0.3010 - val_loss: 0.4487\n",
      "Epoch 6/2000\n",
      "2/2 - 0s - loss: 0.2754 - val_loss: 0.4130\n",
      "Epoch 7/2000\n",
      "2/2 - 0s - loss: 0.2474 - val_loss: 0.3768\n",
      "Epoch 8/2000\n",
      "2/2 - 0s - loss: 0.2235 - val_loss: 0.3405\n",
      "Epoch 9/2000\n",
      "2/2 - 0s - loss: 0.1987 - val_loss: 0.3043\n",
      "Epoch 10/2000\n",
      "2/2 - 0s - loss: 0.1762 - val_loss: 0.2705\n",
      "Epoch 11/2000\n",
      "2/2 - 0s - loss: 0.1514 - val_loss: 0.2399\n",
      "Epoch 12/2000\n",
      "2/2 - 0s - loss: 0.1332 - val_loss: 0.2134\n",
      "Epoch 13/2000\n",
      "2/2 - 0s - loss: 0.1185 - val_loss: 0.1900\n",
      "Epoch 14/2000\n",
      "2/2 - 0s - loss: 0.1070 - val_loss: 0.1706\n",
      "Epoch 15/2000\n",
      "2/2 - 0s - loss: 0.0964 - val_loss: 0.1572\n",
      "Epoch 16/2000\n",
      "2/2 - 0s - loss: 0.0869 - val_loss: 0.1554\n",
      "Epoch 17/2000\n",
      "2/2 - 0s - loss: 0.0866 - val_loss: 0.1613\n",
      "Epoch 18/2000\n",
      "2/2 - 0s - loss: 0.0775 - val_loss: 0.1582\n",
      "Epoch 19/2000\n",
      "2/2 - 0s - loss: 0.0758 - val_loss: 0.1577\n",
      "Epoch 20/2000\n",
      "2/2 - 0s - loss: 0.0743 - val_loss: 0.1570\n",
      "Epoch 21/2000\n",
      "2/2 - 0s - loss: 0.0703 - val_loss: 0.1559\n",
      "Epoch 22/2000\n",
      "2/2 - 0s - loss: 0.0669 - val_loss: 0.1581\n",
      "Epoch 23/2000\n",
      "2/2 - 0s - loss: 0.0662 - val_loss: 0.1586\n",
      "Epoch 24/2000\n",
      "2/2 - 0s - loss: 0.0631 - val_loss: 0.1602\n",
      "Epoch 25/2000\n",
      "2/2 - 0s - loss: 0.0603 - val_loss: 0.1613\n",
      "Epoch 26/2000\n",
      "2/2 - 0s - loss: 0.0604 - val_loss: 0.1625\n",
      "Epoch 27/2000\n",
      "2/2 - 0s - loss: 0.0583 - val_loss: 0.1651\n",
      "Epoch 28/2000\n",
      "2/2 - 0s - loss: 0.0598 - val_loss: 0.1674\n",
      "Epoch 29/2000\n",
      "2/2 - 0s - loss: 0.0584 - val_loss: 0.1669\n",
      "Epoch 30/2000\n",
      "2/2 - 0s - loss: 0.0554 - val_loss: 0.1652\n",
      "Epoch 31/2000\n",
      "2/2 - 0s - loss: 0.0573 - val_loss: 0.1623\n",
      "Epoch 32/2000\n",
      "2/2 - 0s - loss: 0.0540 - val_loss: 0.1541\n",
      "Epoch 33/2000\n",
      "2/2 - 0s - loss: 0.0530 - val_loss: 0.1503\n",
      "Epoch 34/2000\n",
      "2/2 - 0s - loss: 0.0531 - val_loss: 0.1534\n",
      "Epoch 35/2000\n",
      "2/2 - 0s - loss: 0.0516 - val_loss: 0.1561\n",
      "Epoch 36/2000\n",
      "2/2 - 0s - loss: 0.0509 - val_loss: 0.1517\n",
      "Epoch 37/2000\n",
      "2/2 - 0s - loss: 0.0504 - val_loss: 0.1460\n",
      "Epoch 38/2000\n",
      "2/2 - 0s - loss: 0.0499 - val_loss: 0.1425\n",
      "Epoch 39/2000\n",
      "2/2 - 0s - loss: 0.0495 - val_loss: 0.1406\n",
      "Epoch 40/2000\n",
      "2/2 - 0s - loss: 0.0494 - val_loss: 0.1382\n",
      "Epoch 41/2000\n",
      "2/2 - 0s - loss: 0.0485 - val_loss: 0.1347\n",
      "Epoch 42/2000\n",
      "2/2 - 0s - loss: 0.0455 - val_loss: 0.1309\n",
      "Epoch 43/2000\n",
      "2/2 - 0s - loss: 0.0461 - val_loss: 0.1287\n",
      "Epoch 44/2000\n",
      "2/2 - 0s - loss: 0.0459 - val_loss: 0.1290\n",
      "Epoch 45/2000\n",
      "2/2 - 0s - loss: 0.0437 - val_loss: 0.1297\n",
      "Epoch 46/2000\n",
      "2/2 - 0s - loss: 0.0432 - val_loss: 0.1272\n",
      "Epoch 47/2000\n",
      "2/2 - 0s - loss: 0.0429 - val_loss: 0.1247\n",
      "Epoch 48/2000\n",
      "2/2 - 0s - loss: 0.0423 - val_loss: 0.1223\n",
      "Epoch 49/2000\n",
      "2/2 - 0s - loss: 0.0419 - val_loss: 0.1189\n",
      "Epoch 50/2000\n",
      "2/2 - 0s - loss: 0.0405 - val_loss: 0.1176\n",
      "Epoch 51/2000\n",
      "2/2 - 0s - loss: 0.0397 - val_loss: 0.1163\n",
      "Epoch 52/2000\n",
      "2/2 - 0s - loss: 0.0384 - val_loss: 0.1143\n",
      "Epoch 53/2000\n",
      "2/2 - 0s - loss: 0.0388 - val_loss: 0.1142\n",
      "Epoch 54/2000\n",
      "2/2 - 0s - loss: 0.0391 - val_loss: 0.1105\n",
      "Epoch 55/2000\n",
      "2/2 - 0s - loss: 0.0362 - val_loss: 0.1071\n",
      "Epoch 56/2000\n",
      "2/2 - 0s - loss: 0.0395 - val_loss: 0.1042\n",
      "Epoch 57/2000\n",
      "2/2 - 0s - loss: 0.0365 - val_loss: 0.1027\n",
      "Epoch 58/2000\n",
      "2/2 - 0s - loss: 0.0361 - val_loss: 0.1013\n",
      "Epoch 59/2000\n",
      "2/2 - 0s - loss: 0.0358 - val_loss: 0.1005\n",
      "Epoch 60/2000\n",
      "2/2 - 0s - loss: 0.0353 - val_loss: 0.1011\n",
      "Epoch 61/2000\n",
      "2/2 - 0s - loss: 0.0356 - val_loss: 0.1013\n",
      "Epoch 62/2000\n",
      "2/2 - 0s - loss: 0.0340 - val_loss: 0.1004\n",
      "Epoch 63/2000\n",
      "2/2 - 0s - loss: 0.0341 - val_loss: 0.0983\n",
      "Epoch 64/2000\n",
      "2/2 - 0s - loss: 0.0339 - val_loss: 0.0971\n",
      "Epoch 65/2000\n",
      "2/2 - 0s - loss: 0.0341 - val_loss: 0.0957\n",
      "Epoch 66/2000\n",
      "2/2 - 0s - loss: 0.0334 - val_loss: 0.0956\n",
      "Epoch 67/2000\n",
      "2/2 - 0s - loss: 0.0337 - val_loss: 0.0976\n",
      "Epoch 68/2000\n",
      "2/2 - 0s - loss: 0.0343 - val_loss: 0.0992\n",
      "Epoch 69/2000\n",
      "2/2 - 0s - loss: 0.0338 - val_loss: 0.0986\n",
      "Epoch 70/2000\n",
      "2/2 - 0s - loss: 0.0327 - val_loss: 0.0961\n",
      "Epoch 71/2000\n",
      "2/2 - 0s - loss: 0.0322 - val_loss: 0.0944\n",
      "Epoch 72/2000\n",
      "2/2 - 0s - loss: 0.0317 - val_loss: 0.0954\n",
      "Epoch 73/2000\n",
      "2/2 - 0s - loss: 0.0324 - val_loss: 0.0949\n",
      "Epoch 74/2000\n",
      "2/2 - 0s - loss: 0.0314 - val_loss: 0.0898\n",
      "Epoch 75/2000\n",
      "2/2 - 0s - loss: 0.0313 - val_loss: 0.0872\n",
      "Epoch 76/2000\n",
      "2/2 - 0s - loss: 0.0309 - val_loss: 0.0873\n",
      "Epoch 77/2000\n",
      "2/2 - 0s - loss: 0.0308 - val_loss: 0.0880\n",
      "Epoch 78/2000\n",
      "2/2 - 0s - loss: 0.0310 - val_loss: 0.0883\n",
      "Epoch 79/2000\n",
      "2/2 - 0s - loss: 0.0300 - val_loss: 0.0889\n",
      "Epoch 80/2000\n",
      "2/2 - 0s - loss: 0.0299 - val_loss: 0.0901\n",
      "Epoch 81/2000\n",
      "2/2 - 0s - loss: 0.0308 - val_loss: 0.0903\n",
      "Epoch 82/2000\n",
      "2/2 - 0s - loss: 0.0290 - val_loss: 0.0910\n",
      "Epoch 83/2000\n",
      "2/2 - 0s - loss: 0.0296 - val_loss: 0.0916\n",
      "Epoch 84/2000\n",
      "2/2 - 0s - loss: 0.0300 - val_loss: 0.0919\n",
      "Epoch 85/2000\n",
      "2/2 - 0s - loss: 0.0298 - val_loss: 0.0913\n",
      "Epoch 86/2000\n",
      "2/2 - 0s - loss: 0.0303 - val_loss: 0.0915\n",
      "Epoch 87/2000\n",
      "2/2 - 0s - loss: 0.0291 - val_loss: 0.0926\n",
      "Epoch 88/2000\n",
      "2/2 - 0s - loss: 0.0290 - val_loss: 0.0932\n",
      "Epoch 89/2000\n",
      "2/2 - 0s - loss: 0.0273 - val_loss: 0.0922\n",
      "Epoch 90/2000\n",
      "2/2 - 0s - loss: 0.0298 - val_loss: 0.0906\n",
      "Epoch 91/2000\n",
      "2/2 - 0s - loss: 0.0264 - val_loss: 0.0902\n",
      "Epoch 92/2000\n",
      "2/2 - 0s - loss: 0.0288 - val_loss: 0.0897\n",
      "Epoch 93/2000\n",
      "2/2 - 0s - loss: 0.0275 - val_loss: 0.0905\n",
      "Epoch 94/2000\n",
      "2/2 - 0s - loss: 0.0262 - val_loss: 0.0918\n",
      "Epoch 95/2000\n",
      "2/2 - 0s - loss: 0.0282 - val_loss: 0.0914\n",
      "Epoch 96/2000\n",
      "2/2 - 0s - loss: 0.0275 - val_loss: 0.0910\n",
      "Epoch 97/2000\n",
      "2/2 - 0s - loss: 0.0273 - val_loss: 0.0903\n",
      "Epoch 98/2000\n",
      "2/2 - 0s - loss: 0.0278 - val_loss: 0.0899\n",
      "Epoch 99/2000\n",
      "2/2 - 0s - loss: 0.0272 - val_loss: 0.0897\n",
      "Epoch 100/2000\n",
      "2/2 - 0s - loss: 0.0273 - val_loss: 0.0895\n",
      "Train r2 = 0.6380204224252549\n",
      "Test r2 = -1.9526576440523085e+27\n",
      "Val r2 = -2.2994786127178956e+27\n"
     ]
    }
   ],
   "source": [
    "df_analyst = pd.read_pickle(\"./data/modeling/analyst.pkl\")\n",
    "df_prices = pd.read_pickle(\"./data/modeling/prices.pkl\")\n",
    "\n",
    "df_cronus = pd.concat([df_analyst, df_prices], axis=1)\n",
    "X_cols = list(df_cronus.columns)\n",
    "y_cols = list(df_prices.columns)\n",
    "n_features = len(y_cols)\n",
    "n_days = 1\n",
    "split_point = 250\n",
    "input_shape = (split_point, len(X_cols))\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=input_shape))\n",
    "model.add(Dropout(.3))\n",
    "for i in range(1):\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(.1))\n",
    "model.add(Dense(len(y_cols)))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "model_network(df_cronus, model, X_cols, y_cols, n_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:00:41.475672Z",
     "start_time": "2020-12-05T19:00:41.459683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cols = list(df_cronus.columns)\n",
    "y_cols = list(df_prices.columns)\n",
    "contains(y_cols, X_cols)[1] - contains(y_cols, X_cols)[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:00:11.554675Z",
     "start_time": "2020-12-05T19:00:11.542126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T11:47:34.921552Z",
     "start_time": "2020-12-05T11:47:34.359Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = df[[col for col in df.columns if 'VLO' in col or 'TSLA' in col]]\n",
    "# X_cols = [col for col in df.columns if 'price' not in col]\n",
    "# y_cols = 'price'\n",
    "#X_cols = [col for col in df.columns if 'TSLA' in col]\n",
    "#y_cols = X_cols\n",
    "#X_cols = [col for col in df.columns if 'TSLA' in col and 'price' not in col]\n",
    "\n",
    "df = pd.read_pickle('./data/modeling/model_df.pkl')\n",
    "# X_cols = [col for col in df.columns if 'TSLA_price' not in col]\n",
    "# y_cols = X_cols\n",
    "X_cols = [col for col in df.columns if 'TSLA' in col]\n",
    "y_cols = X_cols\n",
    "n_features = len(y_cols)\n",
    "n_days = 1\n",
    "df.head(1)\n",
    "\n",
    "split_point = 250\n",
    "input_shape = (split_point, len(X_cols))\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=input_shape))\n",
    "model.add(Dropout(.3))\n",
    "for i in range(1):\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(.1))\n",
    "model.add(Dense(len(y_cols)))\n",
    "\n",
    "\n",
    "model_network(df, model, X_cols, y_cols, n_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
